{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch as tc\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from helpers_img import *\n",
    "from NeuralNets import *\n",
    "from training_NN import *\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valerio inizia da qui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loaded a set of images\n",
    "root_dir = \"training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "N = min(100, len(files)) # Load maximum 100 images\n",
    "print(\"Loading \" + str(N) + \" images\")\n",
    "imgs = [load_image(image_dir + files[i]) for i in range(N)]\n",
    "print(files[0])\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(N) + \" images\")\n",
    "gt_imgs = [load_image(gt_dir + files[i]) for i in range(N)]\n",
    "print(files[0])\n",
    "\n",
    "#n = 85 # Only use 85 images for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DatasetUNet(tc.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, bound=None, do_prep=False, do_flip = False,\n",
    "                 normalize = False, noise=False, is_simple_noise=False, rot = False):\n",
    "        self.image_dir = root_dir + \"images/\"\n",
    "        self.files = os.listdir(self.image_dir)\n",
    "        self.gt_dir = root_dir + \"groundtruth/\"\n",
    "        self.do_prep = do_prep\n",
    "        self.do_flip = do_flip\n",
    "        self.normalize = normalize\n",
    "        self.noise = noise\n",
    "        self.is_simple_noise = is_simple_noise\n",
    "        self.rot = rot\n",
    "        if bound!=None:\n",
    "            del self.files[0:bound[0]]\n",
    "            del self.files[-bound[1]:]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def true_len(self):\n",
    "        return len(self.files)*(1+3*self.rot)*(1+1*self.noise)*(1+1*self.do_flip)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = load_image(self.image_dir + self.files[index])\n",
    "        gt_image = load_image(self.gt_dir + self.files[index])\n",
    "        if self.do_prep:\n",
    "            _, laplacian_image = add_laplacian(image)\n",
    "            sobel = add_sobel(image)\n",
    "            segment = add_segment(image)\n",
    "            image=np.concatenate((image,laplacian_image,sobel,segment),axis = 2)\n",
    "        image,gt_image=[image],[gt_image]\n",
    "        if self.rot:\n",
    "            image,gt_image = rotation(image,gt_image)\n",
    "        if self.do_flip:\n",
    "            image,gt_image = flip(image,gt_image)\n",
    "            \n",
    "        image,gt_image = self.from_list_to_tensor(image), self.from_list_to_tensor(gt_image)\n",
    "        \n",
    "        if self.normalize:\n",
    "            image = (image - image.mean())/image.std()\n",
    "        \n",
    "        if self.noise:\n",
    "            image,gt_image = self.add_noise(image, gt_image, is_simple=self.is_simple_noise)\n",
    "        \n",
    "        return image,gt_image\n",
    "    \n",
    "    def from_list_to_tensor(self,dataset):\n",
    "        ''' cast a list of image in a tensor of appropriate size'''\n",
    "        dataset = np.array(dataset)\n",
    "        try :\n",
    "            N,rows,columns,features = dataset.shape\n",
    "        except:\n",
    "            N,rows,columns = dataset.shape\n",
    "            features=1\n",
    "            dataset=dataset.reshape(N,rows,columns,features)\n",
    "\n",
    "        dataset_tensor = tc.Tensor(N, features, rows, columns)\n",
    "        for j in range(N):\n",
    "            dataset_tensor[j] = tc.tensor(np.array([dataset[j,:,:,i] for i in range(features)]))\n",
    "\n",
    "\n",
    "        return dataset_tensor\n",
    "        \n",
    "    def add_noise(self, dataset,label, is_simple=True):\n",
    "        '''Add noise to the dataset.\n",
    "\n",
    "        dataset : tensor type\n",
    "\n",
    "        label : tensor type'''\n",
    "\n",
    "\n",
    "        if is_simple:\n",
    "\n",
    "            mean, std = dataset.mean(), dataset.std()\n",
    "            # the noise has the 20% of the image standard deviation\n",
    "            noise = np.random.normal(loc = mean, scale = std/5, size = dataset.size())\n",
    "\n",
    "\n",
    "            dataset_with_noise = dataset + tc.tensor(noise).type(tc.FloatTensor)\n",
    "            dataset = tc.cat((dataset,dataset_with_noise),dim = 0)\n",
    "            label = label.type(tc.FloatTensor)\n",
    "            label = tc.cat((label, label), dim = 0)\n",
    "        else:\n",
    "\n",
    "            mean, std = 0, 0.05\n",
    "\n",
    "            noise = np.random.normal(mean, std, size = label.size())\n",
    "\n",
    "            label.type(float)\n",
    "\n",
    "            label_with_noise = label + tc.tensor(noise).type(tc.FloatTensor)\n",
    "\n",
    "            label = tc.cat((label,label_with_noise),dim=0)\n",
    "\n",
    "            dataset = tc.cat((dataset,dataset),dim=0)\n",
    "\n",
    "        return dataset, label\n",
    "    \n",
    "    def get_features(self):\n",
    "        if self.do_prep:\n",
    "            features = 10\n",
    "        else:\n",
    "            features = 3\n",
    "        return features\n",
    "    def get_mini(self):\n",
    "        return (1+3*self.rot)*(1+1*self.do_flip)*(1+1*self.noise)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = iter([0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imgs[0]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = image.mean()\n",
    "std = image.std()\n",
    "\n",
    "noise = np.random.normal(mean,std/5,size = image.shape)\n",
    "image_noise = image + noise\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# augment the dataset adding rotated images\n",
    "imgs, gt_imgs = rotation(imgs, gt_imgs)\n",
    "print('Total number of imgages: '+str(len(imgs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UNet(tc.nn.Module):\n",
    "    def __init__(self,features=3):\n",
    "        super(UNet,self).__init__()\n",
    "        self.is_training=False\n",
    "        self.conv1 = tc.nn.Conv2d(features,8,kernel_size=3)\n",
    "        self.batch1 = tc.nn.BatchNorm2d(8)\n",
    "        self.conv2 = tc.nn.Conv2d(8,8, kernel_size=3)\n",
    "        self.batch2 = tc.nn.BatchNorm2d(8)\n",
    "        self.conv3 = tc.nn.Conv2d(8,16, kernel_size=3)\n",
    "        self.batch3 = tc.nn.BatchNorm2d(16)\n",
    "        self.conv4 = tc.nn.Conv2d(16,16, kernel_size=3)\n",
    "        self.batch4 = tc.nn.BatchNorm2d(16)\n",
    "        self.conv5 = tc.nn.Conv2d(16,16, kernel_size=4)\n",
    "        self.batch5 = tc.nn.BatchNorm2d(16)\n",
    "        self.convUp1 = tc.nn.ConvTranspose2d(16,16,stride=2,kernel_size=2)\n",
    "        self.conv6 = tc.nn.Conv2d(32,16, kernel_size=3)\n",
    "        self.batch6 = tc.nn.BatchNorm2d(16)\n",
    "        self.conv7 = tc.nn.Conv2d(16,16, kernel_size=3)\n",
    "        self.batch7 = tc.nn.BatchNorm2d(16)\n",
    "        self.convUp2 = tc.nn.ConvTranspose2d(16,8,stride=2,kernel_size=2)\n",
    "        self.conv8 = tc.nn.Conv2d(16,8, kernel_size=3)\n",
    "        self.batch8 = tc.nn.BatchNorm2d(8)\n",
    "        self.conv9 = tc.nn.Conv2d(8,8, kernel_size=3)\n",
    "        self.batch9 = tc.nn.BatchNorm2d(8)\n",
    "        self.convUp3 = tc.nn.ConvTranspose2d(8,4,kernel_size=39)\n",
    "        self.conv10 = tc.nn.Conv2d(4,1,kernel_size=3)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.batch1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #x1 = x.clone()\n",
    "        x1 = x\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = x = self.batch2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.batch3(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        #x2 = x.clone()\n",
    "        x2 = x\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = self.batch4(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.batch5(x)\n",
    "        \n",
    "        x = F.relu(self.convUp1(x))\n",
    "        \n",
    "        x= self.adapt_activation(x2,x)\n",
    "        \n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.batch6(x)\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = self.batch7(x)\n",
    "        \n",
    "        x = F.relu(self.convUp2(x))\n",
    "        \n",
    "        x = self.adapt_activation(x1,x)\n",
    "        \n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = self.batch8(x)\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = self.batch9(x)\n",
    "        \n",
    "        x = F.relu(self.convUp3(x))\n",
    "        x = tc.sigmoid(self.conv10(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def adapt_activation(self,x_old,x_new):\n",
    "        '''the function adapts the activation to the smaller one dimensions\n",
    "        and concatenates them'''\n",
    "        \n",
    "        space = (x_old.size(2)- x_new.size(2))//2\n",
    "        \n",
    "        distance = x_new.size(2)\n",
    "        \n",
    "        x_old = x_old.narrow(2,space,distance)\n",
    "        x_old = x_old.narrow(3,space,distance)\n",
    "        \n",
    "        x_new = tc.cat((x_old,x_new),dim=1)\n",
    "        \n",
    "        return x_new\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing_for_UNet(dataset):\n",
    "    # laplace\n",
    "    \n",
    "    for i,image in enumerate(dataset):\n",
    "        _, laplacian_image = add_laplacian(image)\n",
    "        sobel = add_sobel(image)\n",
    "        segment = add_segment(image)\n",
    "        dataset[i]=np.concatenate((image,laplacian_image,sobel,segment),axis = 2)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def from_list_to_tensor(dataset):\n",
    "    ''' cast a list of image in a tensor of appropriate size'''\n",
    "    dataset = np.array(dataset)\n",
    "    try :\n",
    "        N,rows,columns,features = dataset.shape\n",
    "    except:\n",
    "        N,rows,columns = dataset.shape\n",
    "        features=1\n",
    "        dataset=dataset.reshape(N,rows,columns,features)\n",
    "        \n",
    "    dataset_tensor = tc.Tensor(N, features, rows, columns)\n",
    "    for j in range(N):\n",
    "        dataset_tensor[j] = tc.tensor(np.array([dataset[j,:,:,i] for i in range(features)]))\n",
    "    \n",
    "    \n",
    "    return dataset_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_UNet(training_directory, lr, max_epochs, mini_batch_size, nb_test, threshold=0.5, \n",
    "               do_preprocessing = False, flip_data=True, model=None):\n",
    "    ''' train the UNet using the Binary Cross Entropy loss and Adam as optimizer.\n",
    "    The dataset must be a list of 400*400 images.'''\n",
    "    \n",
    "    dataset = DatasetUNet(training_directory, bound=(0,nb_test) ,do_flip=flip_data,\n",
    "                          do_prep= do_preprocessing,\n",
    "                          noise=True, is_simple_noise = True, rot = True, normalize = True)\n",
    "    N = dataset.true_len()\n",
    "    print(N)\n",
    "    test_set = DatasetUNet(training_directory, bound=(nb_test,N) ,do_flip=False,\n",
    "                           do_prep= False,\n",
    "                           noise=False, is_simple_noise = False, rot = False, normalize = True)\n",
    "    train_load = tc.utils.data.DataLoader(dataset,batch_size= mini_batch_size)\n",
    "    test_load = tc.utils.data.DataLoader(test_set,batch_size=nb_test)\n",
    "    if model == None:\n",
    "        model = UNet(features= dataset.get_features())\n",
    "    \n",
    "    optimizer=tc.optim.Adam(model.parameters(),lr)\n",
    "    # maybe using MSE is better\n",
    "    #criterion= tc.nn.BCELoss()\n",
    "    criterion = tc.nn.MSELoss()\n",
    "    training_errors=[]\n",
    "    losses=[]\n",
    "    \n",
    "    if tc.cuda.is_available():\n",
    "        print('cuda is available')\n",
    "        model.cuda()\n",
    "        #criterion.cuda()\n",
    "        #dataset= dataset.cuda()\n",
    "        #label = label.cuda()\n",
    "    \n",
    "    #training_F1_error=[]\n",
    "    #print('starting to train the net')\n",
    "    for epoch in tqdm(range(max_epochs)):\n",
    "        model.train()\n",
    "        #if tc.cuda.is_available():\n",
    "        #    model.cuda()\n",
    "        for input_data, label_data in train_load:\n",
    "            input_data = input_data.view(dataset.get_mini()*mini_batch_size,dataset.get_features(),400,400)\n",
    "            label_data = label_data.view(dataset.get_mini()*mini_batch_size,1,400,400)\n",
    "            if tc.cuda.is_available():\n",
    "                input_data, label_data = input_data.cuda(), label_data.cuda()\n",
    "            output = model(input_data)\n",
    "            #print(output, label_data)\n",
    "            loss = criterion(output, label_data)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tc.cuda.empty_cache()\n",
    "            \n",
    "        \n",
    "        # compute training error\n",
    "        model.eval()\n",
    "        losses.append(loss)\n",
    "        for test,mask in test_load:\n",
    "            test = test.view(test_set.get_mini()*nb_test,test_set.get_features(),400,400)\n",
    "            mask = mask.view(test_set.get_mini()*nb_test,1,400,400)\n",
    "            prediction = model(test)\n",
    "            prediction = prediction.cpu()\n",
    "            prediction = prediction.detach_().numpy()[:,0,:,:]\n",
    "            prediction = (prediction > threshold)*1\n",
    "            #print(prediction[0])\n",
    "            mask = mask.numpy()[:,0,:,:]\n",
    "            F1_error = 0\n",
    "            #print(mask.shape)\n",
    "            training_error = (((mask>0.5)*1 == prediction)*1).sum()/np.prod(prediction.shape)\n",
    "\n",
    "            training_errors.append(training_error)\n",
    "        \n",
    "    model.cpu()\n",
    "    tc.save(model,'Model_UNet/model_CPU.pt')\n",
    "   \n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(epoch + 1)+1,losses)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    try:\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(epoch + 1)+1,training_errors)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('accuracy')\n",
    "    except:\n",
    "        print(training_errors)\n",
    "    return model\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? datasets.ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(tc.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tc.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let's start to train the Net\n",
      "1440\n",
      "cuda is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#test_imgs=imgs[n:N]\n",
    "#test_mask = gt_imgs[n:N]\n",
    "lr = 1e-4\n",
    "max_epochs = 50\n",
    "mini_batch_size=1\n",
    "nb_test = 10\n",
    "print('let\\'s start to train the Net')\n",
    "\n",
    "model = train_UNet('training/', lr, max_epochs, mini_batch_size,nb_test, do_preprocessing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "tc.save(model,'Model_UNet/model_CPU.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = tc.load('Model_UNet/model_CPU.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test on a image\n",
    "image = [imgs[4]]\n",
    "image = preprocessing_for_UNet(image)\n",
    "image = from_list_to_tensor(image)\n",
    "image = (image - image.mean())/image.std()\n",
    "model.eval()\n",
    "prediction = model(image)\n",
    "print(prediction.size())\n",
    "prediction =  prediction.detach_().numpy()[0,0,:,:]\n",
    "prediction = (prediction > 0.5)*1\n",
    "#mask = gt_imgs[20]\n",
    "mask = prediction\n",
    "image = make_img_overlay(imgs[4],mask)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_submission_UNet(test_set, model, name_submission, do_preprocessing= False):\n",
    "    ''' create the submission file for U-Net.\n",
    "    \n",
    "    test_set is a list of images'''\n",
    "    \n",
    "    # preprocessing\n",
    "    \n",
    "    if do_preprocessing:\n",
    "        test_set = preprocessing_for_UNet(test_set)\n",
    "        \n",
    "    # transform list of images in tensor \n",
    "    print('a')\n",
    "    test_set = from_list_to_tensor(test_set)\n",
    "    print('a')\n",
    "    test_set = (test_set- test_set.mean())/test_set.std()\n",
    "    model.eval()\n",
    "    \n",
    "    mini_batch = 10\n",
    "    print('a')\n",
    "    N,channel,w,h = test_set.size()\n",
    "    if tc.cuda.is_available():\n",
    "        model.cuda()\n",
    "    \n",
    "    mask = tc.Tensor(N,1,w,h)\n",
    "    batch_size=10\n",
    "    for i in range(0,test_set.size(0),mini_batch):\n",
    "        temp =  test_set.narrow(0,i,mini_batch)\n",
    "        print(temp.size())\n",
    "        if tc.cuda.is_available():\n",
    "            tc.cuda.empty_cache()\n",
    "            temp = temp.cuda()\n",
    "        temp = model(temp)\n",
    "        mask[i:i+batch_size] = temp.cpu()\n",
    "    print('a')\n",
    "    mask = (mask.detach().numpy() > 0.5)*1\n",
    "    list_of_names= []\n",
    "    for i in range(N):\n",
    "        plt.imsave( \"prediction_\"+str(i+1)+\".png\", mask[i], cmap = matplotlib.cm.gray)\n",
    "        list_of_names.append(\"prediction_\"+str(i+1)+\".png\")\n",
    "    masks_to_submission(name_submission, *list_of_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loaded a set of images\n",
    "root_dir_test = \"test_set_images/\"\n",
    "imgs_test = []\n",
    "for l in range(1,51):\n",
    "    dir_test = root_dir_test + 'test_'+str(l)+'/'\n",
    "    files_test = os.listdir(dir_test)\n",
    "    img_test = load_image(dir_test + files_test[0])\n",
    "    imgs_test.append(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_submission_UNet(imgs_test, model, 'third_submission.csv', do_preprocessing= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=90*3\n",
    "N=len(imgs)\n",
    "train_imgs=imgs[0:n]\n",
    "train_mask=gt_imgs[0:n]\n",
    "test_imgs=imgs[n:N]\n",
    "test_mask = gt_imgs[n:N]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp=concatenate_images(train_imgs[3], train_mask[3])\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? tc.nn.Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(train_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(test_imgs),N-n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare input data \n",
    "w=16\n",
    "h=16\n",
    "train_sub_images=[img_crop(train_imgs[i], w, h) for i in range(n)]\n",
    "train_mask_label=[img_crop(train_mask[i],w,h) for i in range(n)]\n",
    "train_mask_label=from_mask_to_vector(train_mask_label,0.3)\n",
    "test_sub_images=[img_crop(test_imgs[i], w, h) for i in range(N-n)]\n",
    "#test_mask_label=[img_crop(train_mask[n+i],w,h) for i in range(n)]\n",
    "#test_mask_label=from_mask_to_vector(test_mask_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? Image.fromarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print((1*train_mask_label).sum()/len(train_mask_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(train_sub_images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sub_images = transform_subIMG_to_Tensor(train_sub_images)\n",
    "test_sub_images = transform_subIMG_to_Tensor(test_sub_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# normalize data\n",
    "mean = train_sub_images.mean()\n",
    "std = train_sub_images.std()\n",
    "train_sub_images = (train_sub_images-mean)/std\n",
    "train_sub_images, train_mask_label = reduce_dataset(train_sub_images,train_mask_label)\n",
    "#print(train_sub_images[-1]-train_sub_images[-2])\n",
    "for l in range(n):\n",
    "    new_indices= np.random.permutation(len(train_mask_label))\n",
    "    train_sub_images=train_sub_images[new_indices]\n",
    "    train_mask_label=train_mask_label[new_indices]\n",
    "#print(train_sub_images[0]-train_sub_images[1])\n",
    "#train_sub_images.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " ? tc.Tensor.narrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_mask_label.sum()/len(train_mask_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SimpleNet(0)\n",
    "lr=1e-4\n",
    "max_epochs=15\n",
    "mini_batch_size=1\n",
    "\n",
    "train_model_Adam( model, train_sub_images, train_mask_label, max_epochs, lr, mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(tc.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? tc.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N1=625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the result on a single image\n",
    "#N1=int(train_sub_images.size(0)/n)\n",
    "image_test= test_sub_images.narrow(0,43*N1,N1)\n",
    "image_test=(image_test-mean)/std\n",
    "mask_array=model(image_test)\n",
    "#print(mask_array.max())\n",
    "mask_list=mask_array[:]>0.5\n",
    "mask_test = label_to_img(400, 400, 16, 16, mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute F1 score\n",
    "mask=gt_imgs[n]\n",
    "#print(mask.sum())\n",
    "print(calcul_F1(mask, mask_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# overlap images\n",
    "\n",
    "print_img = make_img_overlay(imgs[n+43], mask_test)\n",
    "#print_img = make_img_overlay(imgs[n+43], gt_imgs[n+43])\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(print_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_test_error(test_dataset, test_label, nb_patches, model):\n",
    "    ''' compute the F1 error made during road segmentation. \n",
    "    Exemple: for a 16*16 patch we have that nb_patches=625'''\n",
    "    model.is_train=False\n",
    "    mean=test_dataset.mean()\n",
    "    std= test_dataset.std()\n",
    "    test_dataset = (test_dataset-mean)/std\n",
    "    test_output = model(test_dataset)\n",
    "    w = int(400/np.sqrt(nb_patches))\n",
    "    F1_error=np.zeros(int(test_dataset.size(0)/nb_patches))\n",
    "    for i in range(int(test_dataset.size(0)/nb_patches)):\n",
    "        mask = test_output.narrow(0,i*nb_patches, nb_patches)\n",
    "        mask = mask.detach().numpy()[:]>0.5\n",
    "        mask = label_to_img(400, 400, w, w, mask)\n",
    "        F1_error[i] = calcul_F1(test_label[i], mask)\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(int(test_dataset.size(0)/nb_patches))+1,F1_error)\n",
    "    plt.xlabel('image')\n",
    "    plt.ylabel('F1_error')\n",
    "    F1_mean= np.mean(F1_error)\n",
    "    return F1_mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F1=compute_test_error(test_sub_images, test_mask, 625, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
