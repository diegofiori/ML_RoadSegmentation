{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch as tc\n",
    "from helpers_img import *\n",
    "from NeuralNets import *\n",
    "from training_NN import *\n",
    "from Post_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded a set of images\n",
    "root_dir = \"training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "N = min(100, len(files)) # Load maximum 100 images\n",
    "print(\"Loading \" + str(N) + \" images\")\n",
    "imgs = [load_image(image_dir + files[i]) for i in range(N)]\n",
    "print(files[0])\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(N) + \" images\")\n",
    "gt_imgs = [load_image(gt_dir + files[i]) for i in range(N)]\n",
    "print(files[0])\n",
    "\n",
    "#n = 85 # Only use 85 images for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment the dataset adding rotated images\n",
    "imgs, gt_imgs = rotation(imgs, gt_imgs)\n",
    "print('Total number of imgages: '+str(len(imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(root_dir)\n",
    "del(image_dir)\n",
    "del(files)\n",
    "del(N)\n",
    "del(gt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_images(imgs, gt_imgs,size,number):\n",
    "    '''This function returns a list of list. Each element of the \"external\" list is a list of randomly \n",
    "    sampled images with replacement'''\n",
    "    \n",
    "    new_imgs=[]\n",
    "    new_gt_imgs=[]\n",
    "    array = np.arange(len(imgs))\n",
    "    matrix= np.zeros((len(imgs),number))\n",
    "    for k in range(number):\n",
    "        b = np.random.choice(array, size, replace=True)\n",
    "        list_temp_imgs = [imgs[i] for i in b]\n",
    "        list_temp_gt_imgs = [gt_imgs[i] for i in b]\n",
    "        new_imgs.append(list_temp_imgs)\n",
    "        new_gt_imgs.append(list_temp_gt_imgs)\n",
    "        matrix[b,k]=1\n",
    "    \n",
    "    return new_imgs,new_gt_imgs,matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SimpleNet(dataset, label, w, h, lr, max_epochs, mini_batch_size, dropout):\n",
    "    ''' Train a simple net'''\n",
    "    n = len(dataset)\n",
    "    train_sub_images = [img_crop(dataset[i], w, h) for i in range(n)]\n",
    "    train_mask_label = [img_crop(label[i],w,h) for i in range(n)]\n",
    "    train_mask_label = from_mask_to_vector(train_mask_label,0.3)\n",
    "    train_sub_images = transform_subIMG_to_Tensor(train_sub_images)\n",
    "    mean = train_sub_images.mean()\n",
    "    std = train_sub_images.std()\n",
    "    train_sub_images = (train_sub_images-mean)/std\n",
    "    train_sub_images, train_mask_label = reduce_dataset(train_sub_images,train_mask_label)\n",
    "    # shuffle images\n",
    "    for l in range(10):\n",
    "        new_indices= np.random.permutation(len(train_mask_label))\n",
    "        train_sub_images=train_sub_images[new_indices]\n",
    "        train_mask_label=train_mask_label[new_indices]\n",
    "    \n",
    "    model = SimpleNet(dropout)\n",
    "    \n",
    "    mini_batch_rest = train_sub_images.size(0) % mini_batch_size\n",
    "    \n",
    "    if mini_batch_rest > 0:\n",
    "        train_sub_images = train_sub_images.narrow(0,0,train_sub_images.size(0)-mini_batch_rest)\n",
    "        train_mask_label = train_mask_label[0:train_sub_images.size(0)]\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    train_model_Adam( model, train_sub_images, train_mask_label, max_epochs, lr, mini_batch_size)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_NN(dataset, label, percentage_train_data, nb_model, w, h, lr, max_epochs, mini_batch_size, dropout):\n",
    "    nb_data = int( len(dataset)*percentage_train_data )\n",
    "    list_dataset, list_label, data_matrix = bootstrap_images(dataset, label, nb_data, nb_model)\n",
    "    models = []\n",
    "    for i in range(nb_model):\n",
    "        model=train_SimpleNet(list_dataset[i], list_label[i], w, h, lr, max_epochs, mini_batch_size, dropout)\n",
    "        models.append(model)\n",
    "        print('model '+str(i)+' trained')\n",
    "        \n",
    "    data_matrix = 1 - data_matrix\n",
    "    # the data matrix has 1 in position n,j if the nth image was not used in jth\n",
    "    # model training.\n",
    "    \n",
    "    # compute F1 error\n",
    "    \n",
    "    test_imgs=[img_crop(dataset[k], w, h) for k in range(len(dataset))]\n",
    "    nb_patches=len(test_imgs[0])\n",
    "    test_imgs = transform_subIMG_to_Tensor(test_imgs)\n",
    "    mean=test_imgs.mean()\n",
    "    std= test_imgs.std()\n",
    "    test_imgs = (test_imgs-mean)/std\n",
    "    F1_error=0\n",
    "    not_testable_img=0\n",
    "    for i in range(len(dataset)):\n",
    "        image= test_imgs.narrow(0,i*nb_patches,nb_patches)\n",
    "        if data_matrix[i,:].sum()>0:\n",
    "            ind=np.where(data_matrix[i,:])[0]\n",
    "            predictions=[models[k](image).detach().numpy() for k in ind]\n",
    "            predictions = np.array(predictions)\n",
    "            predictions = ((predictions.mean(0)[:] >0.5)*1).reshape(-1,)\n",
    "            mask_test = label_to_img(400, 400, w, h, predictions)\n",
    "            F1_error += calcul_F1(label[i], mask_test)\n",
    "        else:\n",
    "            not_testable_img+=1\n",
    "    \n",
    "    F1_error= F1_error/(len(dataset)-not_testable_img)\n",
    "    return models, F1_error\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_Adam( model, train_data, label, max_epochs, lr, mini_batch_size, threshold=0.01):\n",
    "    '''train the Neural Net using Adam as optimizer and an MSE loss'''\n",
    "    #optimizer=tc.optim.SGD(model.parameters(),lr)\n",
    "    optimizer=tc.optim.Adam(model.parameters(),lr)\n",
    "    criterion= tc.nn.MSELoss()\n",
    "    training_errors=[]\n",
    "    if tc.cuda.is_available():\n",
    "        tc.cuda.empty_cache()\n",
    "        model.cuda()\n",
    "        train_data = train_data.cuda()\n",
    "    \n",
    "    for epoch in tqdm(range(max_epochs)):\n",
    "        model.is_training=True\n",
    "        model.train()\n",
    "        if tc.cuda.is_available():\n",
    "            tc.cuda.empty_cache()\n",
    "        for i in range(0,train_data.size(0),mini_batch_size):\n",
    "            output= model(train_data.narrow(0,i,mini_batch_size))\n",
    "            #print(output,tc.LongTensor(np.array([1*label[i:i+mini_batch_size]]).reshape(-1,1)))\n",
    "            temp=tc.FloatTensor(np.array([1*label[i:i+mini_batch_size]]).reshape(-1,1))\n",
    "            \n",
    "            temp = temp.cuda()\n",
    "            loss= criterion(output,temp)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # compute training error\n",
    "        model.is_training=False\n",
    "        model.eval()\n",
    "        test = model(train_data)\n",
    "        test = test.cpu()\n",
    "        prediction= test[:]>0.5\n",
    "        \n",
    "        prediction= 1*(prediction.numpy()[:] != label.reshape(-1,1)[:])\n",
    "        \n",
    "        training_error = np.sum(prediction)/len(prediction)\n",
    "        training_errors.append(training_error*100)\n",
    "        if training_error< threshold:\n",
    "            break\n",
    "        \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(epoch+1)+1,training_errors)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('error [%]')\n",
    "    plt.show()\n",
    "        \n",
    "    model.cpu()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# valerio modifica questo\n",
    "percentage_train_data=0.1\n",
    "nb_model=10\n",
    "w=16\n",
    "h=16\n",
    "lr=1e-4\n",
    "max_epochs=20\n",
    "mini_batch_size=10\n",
    "dropout=0\n",
    "models, F1_error= bagging_NN(imgs, gt_imgs, percentage_train_data, nb_model, w, h, lr, max_epochs, mini_batch_size, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F1_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,model in enumerate(models):\n",
    "    tc.save(model,f'Model_Bagging/model{i}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]\n",
    "for i in range(10):\n",
    "    model = tc.load(f'Model_Bagging/model{i}.pt')\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = imgs[30]\n",
    "mask= gt_imgs[30]\n",
    "test_img = [img_crop(test_img, 16,16)]\n",
    "test_img = transform_subIMG_to_Tensor(test_img)\n",
    "mean=test_img.mean()\n",
    "std= test_img.std()\n",
    "test_img = (test_img-mean)/std\n",
    "result=np.zeros((test_img.size(0),))\n",
    "for model in models:\n",
    "    result += model(test_img).detach_().numpy().reshape(-1,)\n",
    "\n",
    "result = result / len(models)\n",
    "result = (result > 0.5)*1\n",
    "\n",
    "\n",
    "image = imgs[30]\n",
    "\n",
    "mask_res = label_to_img(400, 400, 16, 16, result)\n",
    "image_plot = make_img_overlay(image, mask_res)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image_plot)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_image_test(test_image, models):\n",
    "    ''' take a 608 * 608 image'''\n",
    "    image_original = test_image\n",
    "    test_image = img_crop(test_image,16,16)\n",
    "    test_image = transform_subIMG_to_Tensor([test_image])\n",
    "    mean=test_image.mean()\n",
    "    std= test_image.std()\n",
    "    test_image = (test_image-mean)/std\n",
    "    predictions=[]\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        predictions.append(model(test_image).detach().numpy().reshape(-1,))\n",
    "    \n",
    "    predictions = np.array(predictions).mean(0)\n",
    "    predictions = predictions > 0.5\n",
    "    # add there the postprocessing\n",
    "    predictions = post_processing(predictions,27,8,3,3,38)\n",
    "    ###############################################\n",
    "    predictions=label_to_img(608, 608, 16, 16, predictions)\n",
    "    \n",
    "    image = make_img_overlay(image_original, predictions)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded a set of images\n",
    "root_dir_test = \"test_set_images/\"\n",
    "imgs_test = []\n",
    "for l in range(1,51):\n",
    "    dir_test = root_dir_test + 'test_'+str(l)+'/'\n",
    "    files_test = os.listdir(dir_test)\n",
    "    img_test = load_image(dir_test + files_test[0])\n",
    "    imgs_test.append(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print_image_test(imgs_test[16], models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(test_data, models, w, h, name_file, prediction_training_dir, normalize=True):\n",
    "    ''' the function takes as input the test data and the models used for prediction. \n",
    "    If a list of model is given, the prediction will be done with majority vote. \n",
    "    \n",
    "    The function is written explicitly for prediction using SimpleNet model.\n",
    "    \n",
    "    test_data: list of images.\n",
    "    \n",
    "    models: list of models or single model\n",
    "    \n",
    "    w, h: width and high of the patches'''\n",
    "    \n",
    "    # from list to Tensor\n",
    "    w_im, h_im,_ = test_data[0].shape\n",
    "    test_data = [img_crop(test_data[k], w, h) for k in range(len(test_data))]\n",
    "    \n",
    "    test_data = transform_subIMG_to_Tensor(test_data)\n",
    "    \n",
    "    if normalize:\n",
    "        \n",
    "        test_data = (test_data-test_data.mean())/test_data.std()\n",
    "    \n",
    "    try :\n",
    "        nb_models = len(models)\n",
    "        prediction = [] \n",
    "        for i in range(nb_models):\n",
    "            models[i].eval()\n",
    "            prediction.append((models[i](test_data)).detach().numpy())\n",
    "            \n",
    "        prediction = np.array(prediction)\n",
    "        prediction = (prediction.sum(0)/nb_models > 0.5)*1\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        prediction = models(test_data).detach().numpy()\n",
    "        \n",
    "        prediction = 1*(prediction > 0.5)\n",
    "     \n",
    "    prediction = prediction.reshape(-1,)\n",
    "    \n",
    "    nb_patches = int(w_im*h_im/(w*h))\n",
    "    nb_images =int(prediction.shape[0]/nb_patches)\n",
    "    list_of_mask = [prediction[i*nb_patches:(i+1)*nb_patches ] for i in range(nb_images)]\n",
    "    for k in range(len(list_of_mask)):\n",
    "        list_of_mask[k] = post_processing(list_of_mask[k],27,8,3,3,38)\n",
    "    # from patch to image\n",
    "    list_of_masks=[label_to_img(w_im, h_im, w, h, list_of_mask[k]) for k in range(nb_images)]\n",
    "    list_of_string_names = []\n",
    "    for i,gt_image in enumerate(list_of_masks):\n",
    "        plt.imsave(prediction_training_dir+f\"prediction_{i+1}.png\",gt_image, cmap=matplotlib.cm.gray)\n",
    "        list_of_string_names.append(prediction_training_dir+\"prediction_\" + str(i+1) + \".png\")\n",
    "    \n",
    "    # create file submission\n",
    "    masks_to_submission(name_file, *list_of_string_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(imgs_test, models, w, h, 'first_submission.csv', '', normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
