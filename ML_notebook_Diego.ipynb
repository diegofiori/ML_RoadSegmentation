{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch as tc\n",
    "from helpers_img import *\n",
    "from NeuralNets import *\n",
    "from training_NN import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valerio inizia da qui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 100 images\n",
      "satImage_001.png\n",
      "Loading 100 images\n",
      "satImage_001.png\n"
     ]
    }
   ],
   "source": [
    "# Loaded a set of images\n",
    "root_dir = \"training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "N = min(100, len(files)) # Load maximum 100 images\n",
    "print(\"Loading \" + str(N) + \" images\")\n",
    "imgs = [load_image(image_dir + files[i]) for i in range(N)]\n",
    "print(files[0])\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(N) + \" images\")\n",
    "gt_imgs = [load_image(gt_dir + files[i]) for i in range(N)]\n",
    "print(files[0])\n",
    "\n",
    "#n = 85 # Only use 85 images for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of imgages: 400\n"
     ]
    }
   ],
   "source": [
    "# augment the dataset adding rotated images\n",
    "imgs, gt_imgs = rotation(imgs, gt_imgs)\n",
    "print('Total number of imgages: '+str(len(imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bootstrap_images(imgs, gt_imgs,size,number):\n",
    "    '''This function returns a list of list. Each element of the \"external\" list is a list of randomly \n",
    "    sampled images with replacement'''\n",
    "    \n",
    "    new_imgs=[]\n",
    "    new_gt_imgs=[]\n",
    "    array = np.arange(len(imgs))\n",
    "    matrix= np.zeros((len(imgs),number))\n",
    "    for k in range(number):\n",
    "        b = np.random.choice(array, size, replace=True)\n",
    "        list_temp_imgs = [imgs[i] for i in b]\n",
    "        list_temp_gt_imgs = [gt_imgs[i] for i in b]\n",
    "        new_imgs.append(list_temp_imgs)\n",
    "        new_gt_imgs.append(list_temp_gt_imgs)\n",
    "        matrix[b,k]=1\n",
    "    \n",
    "    return new_imgs,new_gt_imgs,matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_SimpleNet(dataset, label, w, h, lr, max_epochs, mini_batch_size, dropout):\n",
    "    ''' Train a simple net'''\n",
    "    n = len(dataset)\n",
    "    train_sub_images = [img_crop(dataset[i], w, h) for i in range(n)]\n",
    "    train_mask_label = [img_crop(label[i],w,h) for i in range(n)]\n",
    "    train_mask_label = from_mask_to_vector(train_mask_label,0.3)\n",
    "    train_sub_images = transform_subIMG_to_Tensor(train_sub_images)\n",
    "    mean = train_sub_images.mean()\n",
    "    std = train_sub_images.std()\n",
    "    train_sub_images = (train_sub_images-mean)/std\n",
    "    train_sub_images, train_mask_label = reduce_dataset(train_sub_images,train_mask_label)\n",
    "    # shuffle images\n",
    "    for l in range(10):\n",
    "        new_indices= np.random.permutation(len(train_mask_label))\n",
    "        train_sub_images=train_sub_images[new_indices]\n",
    "        train_mask_label=train_mask_label[new_indices]\n",
    "    \n",
    "    model = SimpleNet(dropout)\n",
    "    \n",
    "\n",
    "    train_model_Adam( model, train_sub_images, train_mask_label, max_epochs, lr, mini_batch_size)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bagging_NN(dataset, label, percentage_train_data, nb_model, w, h, lr, max_epochs, mini_batch_size, dropout):\n",
    "    nb_data = int( len(dataset)*percentage_train_data )\n",
    "    list_dataset, list_label, data_matrix = bootstrap_images(dataset, label, nb_data, nb_model)\n",
    "    models = []\n",
    "    for i in range(nb_model):\n",
    "        model=train_SimpleNet(list_dataset[i], list_label[i], w, h, lr, max_epochs, mini_batch_size, dropout)\n",
    "        models.append(model)\n",
    "        print('model '+str(i)+' trained')\n",
    "        \n",
    "    data_matrix = 1 - data_matrix\n",
    "    # the data matrix has 1 in position n,j if the nth image was not used in jth\n",
    "    # model training.\n",
    "    \n",
    "    # compute F1 error\n",
    "    \n",
    "    test_imgs=[img_crop(dataset[k], w, h) for k in range(len(dataset))]\n",
    "    nb_patches=len(test_imgs[0])\n",
    "    test_imgs = transform_subIMG_to_Tensor(test_imgs)\n",
    "    F1_error=0\n",
    "    not_testable_img=0\n",
    "    for i in range(len(dataset)):\n",
    "        image= test_imgs.narrow(0,i*nb_patches,nb_patches)\n",
    "        if data_matrix[i,:].sum()>0:\n",
    "            ind=np.where(data_matrix[i,:])[0]\n",
    "            predictions=[models[k](image).detach().numpy() for k in ind]\n",
    "            predictions = np.array(predictions)\n",
    "            predictions = predictions.mean(0)[:] >0.5\n",
    "            mask_test = label_to_img(400, 400, w, h, predictions)\n",
    "            F1_error += calcul_F1(label[i], mask_test)\n",
    "        else:\n",
    "            not_testable_img+=1\n",
    "    \n",
    "    F1_error= F1_error/(len(dataset)-not_testable_img)\n",
    "    return models, F1_error\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# valerio modifica questo\n",
    "percentage_train_data=0.05\n",
    "nb_model=2\n",
    "w=16\n",
    "h=16\n",
    "lr=1e-4\n",
    "max_epochs=2\n",
    "mini_batch_size=1\n",
    "dropout=0\n",
    "models, F1_error= bagging_NN(imgs, gt_imgs, percentage_train_data, nb_model, w, h, lr, max_epochs, mini_batch_size, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=np.array([[0,0],[0,1]])\n",
    "ind= np.where(a[1,:])\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valerio fermati qui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tc.tensor([0,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? tc.nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UNet(tc.nn.Module):\n",
    "    def __init__(self,features=3):\n",
    "        super(UNet,self).__init__()\n",
    "        self.is_training=False\n",
    "        self.conv1 = tc.nn.Conv2d(features,8,kernel_size=3)\n",
    "        self.batch1 = tc.nn.BatchNorm2d(8)\n",
    "        self.conv2 = tc.nn.Conv2d(8,8, kernel_size=3)\n",
    "        self.batch2 = tc.nn.BatchNorm2d(8)\n",
    "        self.conv3 = tc.nn.Conv2d(8,16, kernel_size=3)\n",
    "        self.batch3 = tc.nn.BatchNorm2d(16)\n",
    "        self.conv4 = tc.nn.Conv2d(16,16, kernel_size=3)\n",
    "        self.batch4 = tc.nn.BatchNorm2d(16)\n",
    "        self.conv5 = tc.nn.Conv2d(16,16, kernel_size=4)\n",
    "        self.batch5 = tc.nn.BatchNorm2d(16)\n",
    "        self.convUp1 = tc.nn.ConvTranspose2d(16,16,stride=2,kernel_size=2)\n",
    "        self.conv6 = tc.nn.Conv2d(32,16, kernel_size=3)\n",
    "        self.batch6 = tc.nn.BatchNorm2d(16)\n",
    "        self.conv7 = tc.nn.Conv2d(16,16, kernel_size=3)\n",
    "        self.batch7 = tc.nn.BatchNorm2d(16)\n",
    "        self.convUp2 = tc.nn.ConvTranspose2d(16,8,stride=2,kernel_size=2)\n",
    "        self.conv8 = tc.nn.Conv2d(16,8, kernel_size=3)\n",
    "        self.batch8 = tc.nn.BatchNorm2d(8)\n",
    "        self.conv9 = tc.nn.Conv2d(8,8, kernel_size=3)\n",
    "        self.batch9 = tc.nn.BatchNorm2d(8)\n",
    "        self.convUp3 = tc.nn.ConvTranspose2d(8,4,kernel_size=39)\n",
    "        self.conv10 = tc.nn.Conv2d(4,1,kernel_size=3)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.batch1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #x1 = x.clone()\n",
    "        x1 = x\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = x = self.batch2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.batch3(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        #x2 = x.clone()\n",
    "        x2 = x\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = self.batch4(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.batch5(x)\n",
    "        \n",
    "        x = F.relu(self.convUp1(x))\n",
    "        x2= x2.narrow(2,3,188)\n",
    "        x2 = x2.narrow(3,3,188)\n",
    "        x= tc.cat((x,x2),dim=1)\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.batch6(x)\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = self.batch7(x)\n",
    "        \n",
    "        x = F.relu(self.convUp2(x))\n",
    "        x1 = x1.narrow(2,14,368)\n",
    "        x1 = x1.narrow(3,14,368)\n",
    "        x = tc.cat((x1,x),dim=1)\n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = self.batch8(x)\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = self.batch9(x)\n",
    "        \n",
    "        x = F.relu(self.convUp3(x))\n",
    "        x = tc.sigmoid(self.conv10(x))\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "        \n",
    "                                   \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? tc.sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "? np.random.normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_noise(dataset,label, is_simple=True):\n",
    "    '''Add noise to the dataset.\n",
    "    \n",
    "    dataset : tensor type\n",
    "    \n",
    "    label : tensor type'''\n",
    "    \n",
    "    \n",
    "    if is_simple:\n",
    "        \n",
    "        mean, std = dataset.mean(), dataset.std()\n",
    "        noise = np.random.normal(loc = mean, scale = std, size = dataset.size())\n",
    "\n",
    "        dataset_with_noise = dataset + tc.tensor(noise)\n",
    "        dataset = tc.cat((dataset,dataset_with_noise),dim = 0)\n",
    "        label = tc.cat((label, label), dim = 0)\n",
    "    else:\n",
    "        \n",
    "        mean, std = 0, 0.05\n",
    "        \n",
    "        noise = np.random.normal(mean, std, size = label.size())\n",
    "        \n",
    "        label_with_noise = label + tc.tensor(noise)\n",
    "        \n",
    "        label = tc.cat((label,label_with_noise),dim=0)\n",
    "        \n",
    "        dataset = tc.cat((dataset,dataset),dim=0)\n",
    "    \n",
    "    return dataset, label\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def from_list_to_tensor(dataset):\n",
    "    ''' cast a list of image in a tensor of appropriate size'''\n",
    "    dataset = np.array(dataset)\n",
    "    try :\n",
    "        N,rows,columns,features = dataset.shape\n",
    "    except:\n",
    "        N,rows,columns = dataset.shape\n",
    "        features=1\n",
    "        dataset=dataset.reshape(N,rows,columns,features)\n",
    "        \n",
    "    dataset_tensor = tc.Tensor(N, features, rows, columns)\n",
    "    for j in range(N):\n",
    "        dataset_tensor[j] = tc.tensor(np.array([dataset[j,:,:,i] for i in range(features)]))\n",
    "    \n",
    "    \n",
    "    return dataset_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_UNet(dataset, label, lr, max_epochs, mini_batch_size, nb_test, threshold=0.5):\n",
    "    ''' train the UNet using the Binary Cross Entropy loss and Adam as optimizer.\n",
    "    The dataset must be a list of 400*400 images.'''\n",
    "    dataset = from_list_to_tensor(dataset)\n",
    "    mean = dataset.mean()\n",
    "    std = dataset.std()\n",
    "    dataset = (dataset - mean)/ std\n",
    "    test= dataset.narrow(0,dataset.size(0)-nb_test,nb_test)\n",
    "    dataset = dataset.narrow(0,0,dataset.size(0)-nb_test)\n",
    "    label = from_list_to_tensor(label)\n",
    "    test_l = label.narrow(0,dataset.size(0)-nb_test,nb_test)\n",
    "    label = label.narrow(0,0,dataset.size(0)-nb_test)\n",
    "    \n",
    "    ## add is_simple = False to add noise to labels\n",
    "    dataset, label = add_noise(dataset, label)\n",
    "    model = UNet()\n",
    "    \n",
    "    optimizer=tc.optim.Adam(model.parameters(),lr)\n",
    "    # maybe using MSE is better\n",
    "    #criterion= tc.nn.BCELoss()\n",
    "    criterion = tc.nn.MSELoss()\n",
    "    training_errors=[]\n",
    "    losses=[]\n",
    "    \n",
    "    if tc.cuda.is_available():\n",
    "        print('cuda is available')\n",
    "        model.cuda()\n",
    "        #criterion.cuda()\n",
    "        test = test.cuda()\n",
    "        #dataset= dataset.cuda()\n",
    "        #label = label.cuda()\n",
    "    \n",
    "    #training_F1_error=[]\n",
    "    #print('starting to train the net')\n",
    "    for epoch in tqdm(range(max_epochs)):\n",
    "        model.train()\n",
    "        #if tc.cuda.is_available():\n",
    "        #    model.cuda()\n",
    "        for j in range(0,dataset.size(0)-nb_test,mini_batch_size):\n",
    "            input_data = dataset.narrow(0,j,mini_batch_size)\n",
    "            label_data = label.narrow(0,j,mini_batch_size)\n",
    "            if tc.cuda.is_available():\n",
    "                input_data, label_data = input_data.cuda(), label_data.cuda()\n",
    "            output = model(input_data)\n",
    "            #print(output, label_data)\n",
    "            loss = criterion(output, label_data)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tc.cuda.empty_cache()\n",
    "            \n",
    "        \n",
    "        # compute training error\n",
    "        model.eval()\n",
    "        losses.append(loss)\n",
    "        prediction = model(test)\n",
    "        prediction = prediction.cpu()\n",
    "        prediction = prediction.detach_().numpy()[:,0,:,:]\n",
    "        prediction = (prediction > threshold)*1\n",
    "        #print(prediction[0])\n",
    "        mask = test_l.numpy()[:,0,:,:]\n",
    "        F1_error = 0\n",
    "        #print(mask.shape)\n",
    "        training_error = (((mask>0.5)*1 == prediction)*1).sum()/np.prod(prediction.shape)\n",
    "        \n",
    "        training_errors.append(training_error)\n",
    "        \n",
    "        \n",
    "        # improve the calcul_F1 fonction to optimize the code\n",
    "        '''\n",
    "        for i in range(dataset.size(0)):\n",
    "            F1_error += calcul_F1(mask[i], prediction[i])\n",
    "        F1_error = F1_error/dataset.size(0)\n",
    "        training_F1_error.append(F1_error)\n",
    "        if F1_error >0.95:\n",
    "            break\n",
    "        \n",
    "    # plot the results\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(epoch + 1)+1,training_F1_error)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('F1_error')\n",
    "    '''\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(epoch + 1)+1,losses)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(epoch + 1)+1,training_errors)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    return model\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tc.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let's start to train the Net\n",
      "cuda is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 1/15 [03:11<44:35, 191.14s/it]\n",
      "\n",
      "\n",
      "\n",
      " 13%|█▎        | 2/15 [06:22<41:25, 191.20s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-040e63995a7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'let\\'s start to train the Net'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_UNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_imgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-94cbae6ea1e1>\u001b[0m in \u001b[0;36mtrain_UNet\u001b[1;34m(dataset, label, lr, max_epochs, mini_batch_size, nb_test, threshold)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mtc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \"\"\"\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N = len(imgs)\n",
    "n = 400\n",
    "train_imgs=imgs[0:n]\n",
    "train_mask=gt_imgs[0:n]\n",
    "#test_imgs=imgs[n:N]\n",
    "#test_mask = gt_imgs[n:N]\n",
    "lr = 1e-4\n",
    "max_epochs = 15\n",
    "mini_batch_size=10\n",
    "print('let\\'s start to train the Net')\n",
    "model = train_UNet(train_imgs, train_mask, lr, max_epochs, mini_batch_size,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? np.prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test on a image\n",
    "image = [imgs[20]]\n",
    "image = from_list_to_tensor(image)\n",
    "image = (image - image.mean())/image.std()\n",
    "prediction = model(image)\n",
    "prediction =  prediction.detach_().numpy()[0,0,:,:]\n",
    "prediction = (prediction > 0.5)*1\n",
    "#mask = gt_imgs[20]\n",
    "mask = prediction\n",
    "image = make_img_overlay(imgs[20], mask)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=90*3\n",
    "N=len(imgs)\n",
    "train_imgs=imgs[0:n]\n",
    "train_mask=gt_imgs[0:n]\n",
    "test_imgs=imgs[n:N]\n",
    "test_mask = gt_imgs[n:N]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp=concatenate_images(train_imgs[3], train_mask[3])\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? tc.nn.Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(train_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(test_imgs),N-n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare input data \n",
    "w=16\n",
    "h=16\n",
    "train_sub_images=[img_crop(train_imgs[i], w, h) for i in range(n)]\n",
    "train_mask_label=[img_crop(train_mask[i],w,h) for i in range(n)]\n",
    "train_mask_label=from_mask_to_vector(train_mask_label,0.3)\n",
    "test_sub_images=[img_crop(test_imgs[i], w, h) for i in range(N-n)]\n",
    "#test_mask_label=[img_crop(train_mask[n+i],w,h) for i in range(n)]\n",
    "#test_mask_label=from_mask_to_vector(test_mask_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print((1*train_mask_label).sum()/len(train_mask_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(train_sub_images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sub_images = transform_subIMG_to_Tensor(train_sub_images)\n",
    "test_sub_images = transform_subIMG_to_Tensor(test_sub_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# normalize data\n",
    "mean = train_sub_images.mean()\n",
    "std = train_sub_images.std()\n",
    "train_sub_images = (train_sub_images-mean)/std\n",
    "train_sub_images, train_mask_label = reduce_dataset(train_sub_images,train_mask_label)\n",
    "#print(train_sub_images[-1]-train_sub_images[-2])\n",
    "for l in range(n):\n",
    "    new_indices= np.random.permutation(len(train_mask_label))\n",
    "    train_sub_images=train_sub_images[new_indices]\n",
    "    train_mask_label=train_mask_label[new_indices]\n",
    "#print(train_sub_images[0]-train_sub_images[1])\n",
    "#train_sub_images.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " ? tc.Tensor.narrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_mask_label.sum()/len(train_mask_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SimpleNet(0)\n",
    "lr=1e-4\n",
    "max_epochs=15\n",
    "mini_batch_size=1\n",
    "\n",
    "train_model_Adam( model, train_sub_images, train_mask_label, max_epochs, lr, mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(tc.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? tc.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N1=625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the result on a single image\n",
    "#N1=int(train_sub_images.size(0)/n)\n",
    "image_test= test_sub_images.narrow(0,43*N1,N1)\n",
    "image_test=(image_test-mean)/std\n",
    "mask_array=model(image_test)\n",
    "#print(mask_array.max())\n",
    "mask_list=mask_array[:]>0.5\n",
    "mask_test = label_to_img(400, 400, 16, 16, mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute F1 score\n",
    "mask=gt_imgs[n]\n",
    "#print(mask.sum())\n",
    "print(calcul_F1(mask, mask_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# overlap images\n",
    "\n",
    "print_img = make_img_overlay(imgs[n+43], mask_test)\n",
    "#print_img = make_img_overlay(imgs[n+43], gt_imgs[n+43])\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(print_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_test_error(test_dataset, test_label, nb_patches, model):\n",
    "    ''' compute the F1 error made during road segmentation. \n",
    "    Exemple: for a 16*16 patch we have that nb_patches=625'''\n",
    "    model.is_train=False\n",
    "    mean=test_dataset.mean()\n",
    "    std= test_dataset.std()\n",
    "    test_dataset = (test_dataset-mean)/std\n",
    "    test_output = model(test_dataset)\n",
    "    w = int(400/np.sqrt(nb_patches))\n",
    "    F1_error=np.zeros(int(test_dataset.size(0)/nb_patches))\n",
    "    for i in range(int(test_dataset.size(0)/nb_patches)):\n",
    "        mask = test_output.narrow(0,i*nb_patches, nb_patches)\n",
    "        mask = mask.detach().numpy()[:]>0.5\n",
    "        mask = label_to_img(400, 400, w, w, mask)\n",
    "        F1_error[i] = calcul_F1(test_label[i], mask)\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(int(test_dataset.size(0)/nb_patches))+1,F1_error)\n",
    "    plt.xlabel('image')\n",
    "    plt.ylabel('F1_error')\n",
    "    F1_mean= np.mean(F1_error)\n",
    "    return F1_mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F1=compute_test_error(test_sub_images, test_mask, 625, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
