{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch as tc\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from helpers_img import *\n",
    "from NeuralNets import *\n",
    "from training_NN import *\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tc.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valerio inizia da qui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [1,2]\n",
    "b=[*a*4]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DatasetSimpleNet(Dataset):\n",
    "    def __init__(self,root_dir, nb_boot=0, do_flip=False, do_rotation=False,do_train=False):\n",
    "        self.image_dir = root_dir + \"images/\"\n",
    "        self.files = os.listdir(self.image_dir)\n",
    "        self.gt_dir = root_dir + \"groundtruth/\"\n",
    "        self.rot_len=0\n",
    "        self.flip_len=0\n",
    "        self.train = do_train\n",
    "        self.initial_len=len(self.files)\n",
    "        # rotation\n",
    "        if do_rotation:\n",
    "            self.rot_len= len(self.files)\n",
    "            self.files = [*self.files*4]\n",
    "        #flip \n",
    "        if do_flip:\n",
    "            self.flip_len=len(self.files)\n",
    "            self.files= [*self.files*2]\n",
    "        if nb_boot > 0:\n",
    "            if nb_boot<len(self.files):\n",
    "                self.bootstrap_dataset = np.random.choice(np.arange(nb_boot), size =nb_boot,\n",
    "                                                          replace = False)\n",
    "            else :\n",
    "                self.bootstrap_dataset = np.random.choice(np.arange(nb_boot), size =nb_boot,\n",
    "                                                          replace = True)\n",
    "        else :\n",
    "            self.bootstrap_dataset = np.arange(len(self.files))\n",
    "        self.bootstrap_dataset = np.array(self.bootstrap_dataset)\n",
    "        self.binary_vector = np.ones(self.bootstrap_dataset.shape)\n",
    "        \n",
    "        self.binary_vector[self.bootstrap_dataset]=0\n",
    "                \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.bootstrap_dataset.shape[0]\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        ind = self.bootstrap_dataset[index]\n",
    "        image = [load_image(self.image_dir + self.files[ind])]\n",
    "        gt_image = [load_image(self.gt_dir + self.files[ind])]\n",
    "        if self.rot_len>0:\n",
    "            image,gt_image = rotation(image,gt_image)\n",
    "        if self.flip_len>0:\n",
    "            image,gt_image = flip(image,gt_image)\n",
    "        \n",
    "        i = self.bootstrap_dataset.shape[0]//self.initial_len\n",
    "        image,gt_image = image[i],gt_image[i]\n",
    "        w,h=16,16\n",
    "        train_sub_images = [img_crop(image, w, h)]\n",
    "        train_mask_label = [img_crop(gt_image,w,h)]\n",
    "        train_mask_label = from_mask_to_vector(train_mask_label,0.3)\n",
    "        train_sub_images = transform_subIMG_to_Tensor(train_sub_images)\n",
    "        mean = train_sub_images.mean()\n",
    "        std = train_sub_images.std()\n",
    "        train_sub_images = (train_sub_images-mean)/std\n",
    "        if self.train:\n",
    "            train_sub_images, train_mask_label = reduce_dataset(train_sub_images,train_mask_label)\n",
    "            for l in range(10):\n",
    "                new_indices= np.random.permutation(len(train_mask_label))\n",
    "                train_sub_images=train_sub_images[new_indices]\n",
    "                train_mask_label=train_mask_label[new_indices]\n",
    "        return train_sub_images, train_mask_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? np.random.choice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loaded a set of images\n",
    "root_dir = \"training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "N = min(100, len(files)) # Load maximum 100 images\n",
    "print(\"Loading \" + str(N) + \" images\")\n",
    "imgs = [load_image(image_dir + files[i]) for i in range(N)]\n",
    "print(files[0])\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(N) + \" images\")\n",
    "gt_imgs = [load_image(gt_dir + files[i]) for i in range(N)]\n",
    "print(files[0])\n",
    "\n",
    "#n = 85 # Only use 85 images for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# augment the dataset adding rotated images\n",
    "imgs, gt_imgs = rotation(imgs, gt_imgs)\n",
    "print('Total number of imgages: '+str(len(imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bootstrap_images(imgs, gt_imgs,size,number):\n",
    "    '''This function returns a list of list. Each element of the \"external\" list is a list of randomly \n",
    "    sampled images with replacement'''\n",
    "    \n",
    "    new_imgs=[]\n",
    "    new_gt_imgs=[]\n",
    "    array = np.arange(len(imgs))\n",
    "    matrix= np.zeros((len(imgs),number))\n",
    "    for k in range(number):\n",
    "        b = np.random.choice(array, size, replace=True)\n",
    "        list_temp_imgs = [imgs[i] for i in b]\n",
    "        list_temp_gt_imgs = [gt_imgs[i] for i in b]\n",
    "        new_imgs.append(list_temp_imgs)\n",
    "        new_gt_imgs.append(list_temp_gt_imgs)\n",
    "        matrix[b,k]=1\n",
    "    \n",
    "    return new_imgs,new_gt_imgs,matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#? np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_SimpleNet(dataset,lr, max_epochs, mini_batch_size, dropout):\n",
    "    ''' Train a simple net'''\n",
    "    \n",
    "    model = SimpleNet(dropout)\n",
    "    \n",
    "    train_model_Adam( model, dataset, max_epochs, lr, mini_batch_size)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model_Adam( model, dataset, max_epochs, lr, mini_batch_size, threshold=0.01):\n",
    "    '''train the Neural Net using Adam as optimizer and an MSE loss'''\n",
    "    #optimizer=tc.optim.SGD(model.parameters(),lr)\n",
    "    train_loader = DataLoader(dataset,batch_size=mini_batch_size)\n",
    "    optimizer=tc.optim.Adam(model.parameters(),lr)\n",
    "    criterion= tc.nn.MSELoss()\n",
    "    losses=[]\n",
    "    if tc.cuda.is_available():\n",
    "        model.cuda()\n",
    "        \n",
    "    \n",
    "    for i in tqdm(range(max_epochs)):\n",
    "        model.is_training=True\n",
    "        model.train()\n",
    "    \n",
    "        for train_data,label in train_loader:\n",
    "            train_data = train_data.view(-1,3,16,16)\n",
    "            label = label.view(-1,1)\n",
    "            if tc.cuda.is_available():\n",
    "                train_data = train_data.cuda()\n",
    "                label = label.cuda()\n",
    "            output= model(train_data)\n",
    "            #print(output,tc.LongTensor(np.array([1*label[i:i+mini_batch_size]]).reshape(-1,1)))\n",
    "            loss= criterion(output,label)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        losses.append(loss)\n",
    "        # compute training error\n",
    "        '''\n",
    "        model.is_training=False\n",
    "        model.eval()\n",
    "        test = model(train_data)\n",
    "        test = test.cpu()\n",
    "        prediction= test[:]>0.5\n",
    "        \n",
    "        prediction= 1*(prediction.numpy()[:] != label.reshape(-1,1)[:])\n",
    "        \n",
    "        training_error = np.sum(prediction)/len(prediction)\n",
    "        training_errors.append(training_error*100)\n",
    "        if training_error< threshold:\n",
    "            break\n",
    "        \n",
    "    '''\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(epoch+1)+1,losses)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()\n",
    "    \n",
    "    model.cpu()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bagging_NN(root_dir, percentage_train_data, nb_model, w, h, lr, max_epochs, mini_batch_size, dropout):\n",
    "    nb_data = int( 800*percentage_train_data )\n",
    "    list_dataset = [DatasetSimpleNet(root_dir, nb_boot=nb_data, do_flip=True, do_rotation=True)]\n",
    "    models = []\n",
    "    for i in range(nb_model):\n",
    "        model=train_SimpleNet(list_dataset[i], lr, max_epochs, mini_batch_size, dropout)\n",
    "        models.append(model)\n",
    "        print('model '+str(i)+' trained')\n",
    "        \n",
    "    # the data matrix has 1 in position n,j if the nth image was not used in jth\n",
    "    # model training.\n",
    "    \n",
    "    # compute F1 error\n",
    "    \n",
    "        \n",
    "    \n",
    "    F1_error=0\n",
    "    not_testable_img=0\n",
    "    predictions=[]\n",
    "    total_dataset = DatasetSimpleNet(root_dir, nb_boot=0, do_flip=False, do_rotation=False, \n",
    "                                    do_train=False)\n",
    "    #test_loader = DataLoader(dataset)\n",
    "    binary_matrix = np.zeros((total_dataset.__len__(),nb_model))\n",
    "    for i,dataset in enumerate(list_dataset):\n",
    "        binary_matrix[:,i] = dataset.binary_vector\n",
    "    for i in tqdm(range(total_dataset.__len__())):        \n",
    "        if binary_matrix[i,:].sum()>0:\n",
    "            ind=np.where(binary_vector[i,:])[0]\n",
    "            predictions=np.array([models[k](test).detach().numpy() for k in ind])\n",
    "            predictions = ((predictions.mean(0)[:] >0.5)*1).reshape(-1,)\n",
    "            mask_test = label_to_img(400, 400, w, h, predictions)\n",
    "            F1_error += calcul_F1(label[i], mask_test)\n",
    "        else:\n",
    "            not_testable_img+=1\n",
    "    \n",
    "    F1_error= F1_error/(len(dataset)-not_testable_img)\n",
    "    return models, F1_error\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# valerio modifica questo\n",
    "percentage_train_data=0.1\n",
    "nb_model=10\n",
    "w=16\n",
    "h=16\n",
    "lr=1e-4\n",
    "max_epochs=30\n",
    "root_dir = 'training/'\n",
    "mini_batch_size=10\n",
    "dropout=0\n",
    "models, F1_error= bagging_NN(root_dir, percentage_train_data, nb_model, w, h, lr, max_epochs, mini_batch_size, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.zeros((5,1))\n",
    "a[np.array([1,1,1,1,2,2,2,2])]=1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_img = imgs[0]\n",
    "mask= gt_imgs[0]\n",
    "test_img = [img_crop(test_img, 16,16)]\n",
    "test_img = transform_subIMG_to_Tensor(test_img)\n",
    "mean=test_img.mean()\n",
    "std= test_img.std()\n",
    "test_img = (test_img-mean)/std\n",
    "result=np.zeros((test_img.size(0),))\n",
    "for model in models:\n",
    "    result += model(test_img).detach_().numpy().reshape(-1,)\n",
    "\n",
    "result = result / len(models)\n",
    "result = (result > 0.5)*1\n",
    "\n",
    "\n",
    "image = imgs[0]\n",
    "\n",
    "mask_res = label_to_img(400, 400, 16, 16, result)\n",
    "image_plot = make_img_overlay(image, mask_res)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image_plot)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_test_error(test_dataset, test_label, nb_patches, model):\n",
    "    ''' compute the F1 error made during road segmentation. \n",
    "    Exemple: for a 16*16 patch we have that nb_patches=625'''\n",
    "    model.is_train=False\n",
    "    mean=test_dataset.mean()\n",
    "    std= test_dataset.std()\n",
    "    test_dataset = (test_dataset-mean)/std\n",
    "    test_output = model(test_dataset)\n",
    "    w = int(400/np.sqrt(nb_patches))\n",
    "    F1_error=np.zeros(int(test_dataset.size(0)/nb_patches))\n",
    "    for i in range(int(test_dataset.size(0)/nb_patches)):\n",
    "        mask = test_output.narrow(0,i*nb_patches, nb_patches)\n",
    "        mask = mask.detach().numpy()[:]>0.5\n",
    "        mask = label_to_img(400, 400, w, w, mask)\n",
    "        F1_error[i] = calcul_F1(test_label[i], mask)\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(int(test_dataset.size(0)/nb_patches))+1,F1_error)\n",
    "    plt.xlabel('image')\n",
    "    plt.ylabel('F1_error')\n",
    "    F1_mean= np.mean(F1_error)\n",
    "    return F1_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_image_test(test_image, models):\n",
    "    ''' take a 608 * 608 image'''\n",
    "    image_original = test_image\n",
    "    test_image = img_crop(test_image,16,16)\n",
    "    test_image = transform_subIMG_to_Tensor([test_image])\n",
    "    mean=test_image.mean()\n",
    "    std= test_image.std()\n",
    "    test_image = (test_image-mean)/std\n",
    "    predictions=[]\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        predictions.append(model(test_image).detach().numpy().reshape(-1,))\n",
    "    \n",
    "    predictions = np.array(predictions).mean(0)\n",
    "    predictions = predictions > 0.5\n",
    "    # add there the postprocessing\n",
    "    \n",
    "    ###############################################\n",
    "    predictions=label_to_img(608, 608, 16, 16, predictions)\n",
    "    \n",
    "    image = make_img_overlay(image_original, predictions)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loaded a set of images\n",
    "root_dir_test = \"test_set_images/\"\n",
    "imgs_test = []\n",
    "for l in range(1,51):\n",
    "    dir_test = root_dir_test + 'test_'+str(l)+'/'\n",
    "    files_test = os.listdir(dir_test)\n",
    "    img_test = load_image(dir_test + files_test[0])\n",
    "    imgs_test.append(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_image_test(imgs_test[9], models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def complete_lines(label,threshold):\n",
    "    ''' The function controls for each non-road square its neighbors. \n",
    "        If they are classified as ROAD with a certain pattern, the considered square is labeled as ROAD.\n",
    "        \n",
    "        INPUT: List of patches, Vector of label (SAME ORDER)\n",
    "        OUTPUT: New patches, New Vector of label'''\n",
    "    \n",
    "    # Create a matrix of label\n",
    "    label = np.array(label)\n",
    "    label_per_line = int(np.sqrt(label.shape))\n",
    "    matrix_label = label.reshape((label_per_line, label_per_line),order='F')\n",
    "    \n",
    "    # Column with less then 4 zeros are considered as ROAD\n",
    "    #threshold = 16\n",
    "    matrix_label[:,np.where(matrix_label.sum(axis=0)>=threshold)[0]] = 1\n",
    "  \n",
    "    \n",
    "    # Rows with less then 4 zeros are considered as ROAD\n",
    "    #threshold = 16\n",
    "    matrix_label[np.where(matrix_label.sum(axis=1)>=threshold)[0],:] = 1\n",
    "  \n",
    "    # Create the list\n",
    "    list_label = (matrix_label.T).tolist()\n",
    "    # Flatten the lists\n",
    "    label = [y for x in list_label for y in x]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_label = complete_lines(result,16)\n",
    "\n",
    "# DISPLAY THE IMAGE\n",
    "mask_res = label_to_img(400, 400, 16, 16, new_label)\n",
    "image_plot = make_img_overlay(image, mask_res)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_isolated_connected_component(label,size_min):\n",
    "    \n",
    "    # Create a matrix of label\n",
    "    label = np.array(label)\n",
    "    label_per_line = int(np.sqrt(label.shape))\n",
    "    matrix_label = label.reshape((label_per_line, label_per_line),order='F')\n",
    "    \n",
    "    # now identify the objects and remove those above a threshold\n",
    "    Zlabeled,Nlabels = ndimage.measurements.label(matrix_label)\n",
    "    label_size = [(Zlabeled == label).sum() for label in range(Nlabels + 1)]\n",
    "    \n",
    "    # now remove the labels\n",
    "    for label,size in enumerate(label_size):\n",
    "        if size < size_min:\n",
    "            matrix_label[Zlabeled == label] = 0\n",
    "    \n",
    "    # Create the list\n",
    "    list_label = (matrix_label.T).tolist()\n",
    "    # Flatten the lists\n",
    "    label = [y for x in list_label for y in x]\n",
    "    \n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_label2 = remove_isolated_connected_component(new_label,9)\n",
    "\n",
    "# DISPLAY THE IMAGE\n",
    "mask_res = label_to_img(400, 400, 16, 16, new_label2)\n",
    "image_plot = make_img_overlay(image, mask_res)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def complete_lines_almostfull(label):\n",
    "    ''' The function controls for each non-road square its neighbors. \n",
    "        If they are classified as ROAD with a certain pattern, the considered square is labeled as ROAD.\n",
    "        \n",
    "        INPUT: List of labels\n",
    "        OUTPUT: New list of labels'''\n",
    "    \n",
    "    max_zeros = 3\n",
    "    \n",
    "    # Create a matrix of label\n",
    "    label = np.array(label)\n",
    "    label_per_line = int(np.sqrt(label.shape))\n",
    "    matrix_label = label.reshape((label_per_line, label_per_line),order='F')\n",
    "    \n",
    "    # Fix columns\n",
    "    rows,columns = matrix_label.shape\n",
    "    for column in range(columns):\n",
    "        count = 0\n",
    "        start = 0\n",
    "        end = 0\n",
    "        for row in range(rows):\n",
    "            if (matrix_label[row,column] == 1) and (start ==0):\n",
    "                start = 1\n",
    "            elif (matrix_label[row,column] == 1) and (start ==1) and (count>0):\n",
    "                end = 1\n",
    "            elif (matrix_label[row,column] == 0) and (start ==1) and (end==0):\n",
    "                count = count + 1\n",
    "            \n",
    "            if end ==1:\n",
    "                if count < max_zeros:\n",
    "                    matrix_label[row-count:row,column] = 1\n",
    "                start = 1\n",
    "                end = 0\n",
    "                count = 0\n",
    "    \n",
    "    # Fix rows\n",
    "    for row in range(rows):\n",
    "        count = 0\n",
    "        start = 0\n",
    "        end = 0\n",
    "        for column in range(columns):\n",
    "            if (matrix_label[row,column] == 1) and (start ==0):\n",
    "                start = 1\n",
    "            elif (matrix_label[row,column] == 1) and (start ==1) and (count>0):\n",
    "                end = 1\n",
    "            elif (matrix_label[row,column] == 0) and (start ==1) and (end==0):\n",
    "                count = count + 1\n",
    "            \n",
    "            if end ==1:\n",
    "                if count < max_zeros:\n",
    "                    matrix_label[row,column-count:column] = 1\n",
    "                start = 1\n",
    "                end = 0\n",
    "                count = 0\n",
    "    \n",
    "    \n",
    "    # Create the list\n",
    "    list_label = (matrix_label.T).tolist()\n",
    "    # Flatten the lists\n",
    "    label = [y for x in list_label for y in x]\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#new_label3 = complete_lines_almostfull(new_label2)\n",
    "\n",
    "# DISPLAY THE IMAGE\n",
    "#mask_res = label_to_img(400, 400, 16, 16, new_label3)\n",
    "#image_plot = make_img_overlay(image, mask_res)\n",
    "#plt.figure(figsize=(10, 10))\n",
    "#plt.imshow(image_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_garbage_vert(label,max_distance):\n",
    "    \n",
    "    # Create a matrix of label\n",
    "    label = np.array(label)\n",
    "    label_per_line = int(np.sqrt(label.shape))\n",
    "    matrix_label = label.reshape((label_per_line, label_per_line),order='F')\n",
    "    \n",
    "    # Column with all one values\n",
    "    full_columns = np.where(matrix_label.sum(axis=0) == 38)[0]\n",
    "    for column in full_columns:   \n",
    "        if (column < max_distance) and (matrix_label[:,column+1].sum(axis=0) < 38):\n",
    "            count = matrix_label[:,column+1:column+max_distance+1].sum(axis=1)\n",
    "            for k in range(count.shape[0]):\n",
    "                if count[k] < max_distance:\n",
    "                    matrix_label[k,column+1:column+max_distance] = 0\n",
    "        \n",
    "        elif (column > 38 - max_distance) and (matrix_label[:,column-1].sum(axis=0) < 38):\n",
    "            count = matrix_label[:,column-max_distance:column].sum(axis=1)\n",
    "            for k in range(count.shape[0]):\n",
    "                if count[k] < max_distance:\n",
    "                    matrix_label[k,column-max_distance:column] = 0\n",
    "        \n",
    "        elif (column >= max_distance) and (column <= 38 - max_distance):\n",
    "            if matrix_label[:,column+1].sum(axis=0) < 38:\n",
    "                count = matrix_label[:,column+1:column+max_distance+1].sum(axis=1)\n",
    "                for k in range(count.shape[0]):\n",
    "                    if count[k] < max_distance:\n",
    "                        matrix_label[k,column+1:column+max_distance] = 0\n",
    "        \n",
    "            if matrix_label[:,column-1].sum(axis=0) < 38:            \n",
    "                count = matrix_label[:,column-max_distance:column].sum(axis=1)\n",
    "                for k in range(count.shape[0]):\n",
    "                    if count[k] < max_distance:\n",
    "                        matrix_label[k,column-max_distance:column] = 0\n",
    "        \n",
    "    # Rows with less then 4 zeros are considered as ROAD\n",
    "    #threshold = 16\n",
    "    #matrix_label[np.where(matrix_label.sum(axis=1)>=threshold)[0],:] = 1\n",
    "  \n",
    "    # Create the list\n",
    "    list_label = (matrix_label.T).tolist()\n",
    "    # Flatten the lists\n",
    "    label = [y for x in list_label for y in x]\n",
    "    return label    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_label4 = clean_garbage_vert(new_label2,3)\n",
    "\n",
    "# DISPLAY THE IMAGE\n",
    "mask_res = label_to_img(400, 400, 16, 16, new_label4)\n",
    "image_plot = make_img_overlay(image, mask_res)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_garbage_hor(label,max_distance):\n",
    "    \n",
    "    # Create a matrix of label\n",
    "    label = np.array(label)\n",
    "    label_per_line = int(np.sqrt(label.shape))\n",
    "    matrix_label = label.reshape((label_per_line, label_per_line),order='F')\n",
    "    \n",
    "    # Column with all one values\n",
    "    full_rows = np.where(matrix_label.sum(axis=1) == 38)[0]\n",
    "    for row in full_rows:   \n",
    "        if (row < max_distance) and (matrix_label[row+1,:].sum() < 38):\n",
    "            count = matrix_label[row+1:row+max_distance+1,:].sum(axis=0)\n",
    "            for k in range(count.shape[0]):\n",
    "                if count[k] < max_distance:\n",
    "                    matrix_label[row+1:row+max_distance,k] = 0\n",
    "        \n",
    "        elif (row > 38 - max_distance) and (matrix_label[row-1,:].sum() < 38):\n",
    "            count = matrix_label[row-max_distance:row,:].sum(axis=0)\n",
    "            for k in range(count.shape[0]):\n",
    "                if count[k] < max_distance:\n",
    "                    matrix_label[row-max_distance:row,k] = 0\n",
    "        \n",
    "        elif (row >= max_distance) and (row <= 38 - max_distance):\n",
    "            if matrix_label[row+1,:].sum() < 38:\n",
    "                count = matrix_label[row+1:row+max_distance+1,:].sum(axis=0)\n",
    "                for k in range(count.shape[0]):\n",
    "                    if count[k] < max_distance:\n",
    "                        matrix_label[row+1:row+max_distance,k] = 0\n",
    "        \n",
    "            if matrix_label[row-1,:].sum() < 38:            \n",
    "                count = matrix_label[row-max_distance:row,:].sum(axis=0)\n",
    "                for k in range(count.shape[0]):\n",
    "                    if count[k] < max_distance:\n",
    "                        matrix_label[row-max_distance:row,k] = 0\n",
    "        \n",
    "    # Rows with less then 4 zeros are considered as ROAD\n",
    "    #threshold = 16\n",
    "    #matrix_label[np.where(matrix_label.sum(axis=1)>=threshold)[0],:] = 1\n",
    "  \n",
    "    # Create the list\n",
    "    list_label = (matrix_label.T).tolist()\n",
    "    # Flatten the lists\n",
    "    label = [y for x in list_label for y in x]\n",
    "    return label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_label5 = clean_garbage_hor(new_label4,3)\n",
    "\n",
    "# DISPLAY THE IMAGE\n",
    "mask_res = label_to_img(400, 400, 16, 16, new_label5)\n",
    "image_plot = make_img_overlay(image, mask_res)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create mask\n",
    "prevision = label_to_img(400, 400, 16, 16, new_label5)\n",
    "F1=calcul_F1(mask, prevision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valerio fermati qui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def post_processing(label,threshold,size_min,verbarg,horbarg):\n",
    "    label = complete_lines(label,threshold)\n",
    "    label = remove_isolated_connected_component(label,size_min)\n",
    "    label = clean_garbage_vert(label,verbarg)\n",
    "    label = clean_garbage_hor(label,horbarg)\n",
    "    label = remove_isolated_connected_component(label,size_min)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_submission(test_data, models, w, h, name_file, prediction_training_dir, normalize=True):\n",
    "    ''' the function takes as input the test data and the models used for prediction. \n",
    "    If a list of model is given, the prediction will be done with majority vote. \n",
    "    \n",
    "    The function is written explicitly for prediction using SimpleNet model.\n",
    "    \n",
    "    test_data: list of images.\n",
    "    \n",
    "    models: list of models or single model\n",
    "    \n",
    "    w, h: width and high of the patches'''\n",
    "    \n",
    "    # from list to Tensor\n",
    "    w_im, h_im,_ = test_data[0].shape\n",
    "    test_data = [img_crop(test_data[k], w, h) for k in range(len(test_data))]\n",
    "    \n",
    "    test_data = transform_subIMG_to_Tensor(test_data)\n",
    "    \n",
    "    if normalize:\n",
    "        \n",
    "        test_data = (test_data-test_data.mean())/test_data.std()\n",
    "    \n",
    "    try :\n",
    "        nb_models = len(models)\n",
    "        prediction = [] \n",
    "        for i in range(nb_models):\n",
    "            models[i].eval()\n",
    "            prediction.append((models[i](test_data)).detach().numpy())\n",
    "            \n",
    "        prediction = np.array(prediction)\n",
    "        prediction = (prediction.sum(0)/nb_models > 0.5)*1\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        prediction = models(test_data).detach().numpy()\n",
    "        \n",
    "        prediction = 1*(prediction > 0.5)\n",
    "     \n",
    "    prediction = prediction.reshape(-1,)\n",
    "    \n",
    "    nb_patches = int(w_im*h_im/(w*h))\n",
    "    nb_images =int(prediction.shape[0]/nb_patches)\n",
    "    list_of_mask = [prediction[i*nb_patches:(i+1)*nb_patches ] for i in range(nb_images)]\n",
    "    for k in range(len(list_of_mask)):\n",
    "        list_of_mask[k] = post_processing(list_of_mask[k],32,9,3,3)\n",
    "    # from patch to image\n",
    "    list_of_masks=[label_to_img(w_im, h_im, w, h, list_of_mask[k]) for k in range(nb_images)]\n",
    "    list_of_string_names = []\n",
    "    for i,gt_image in enumerate(list_of_masks):\n",
    "        Image.fromarray(gt_image).save(prediction_training_dir + \"prediction_\" + str(i) + \".png\")\n",
    "        list_of_string_names.append(\"prediction_\" + str(i) + \".png\")\n",
    "    # create file submission\n",
    "    masks_to_submission(name_file, *list_of_string_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Image.fromarray(pimg).save(prediction_training_dir + \"prediction_\" + str(i) + \".png\")\n",
    "oimg = get_prediction_with_overlay(train_data_filename, i)\n",
    "oimg.save(prediction_training_dir + \"overlay_\" + str(i) + \".png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "# assign a label to a patch\n",
    "def patch_to_label(patch):\n",
    "    df = np.mean(patch)\n",
    "    if df > foreground_threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def mask_to_submission_strings(image_filename):\n",
    "    \"\"\"Reads a single image and outputs the strings that should go into the submission file\"\"\"\n",
    "    img_number = int(re.search(r\"\\d+\", image_filename).group(0))\n",
    "    im = mpimg.imread(image_filename)\n",
    "    patch_size = 16\n",
    "    for j in range(0, im.shape[1], patch_size):\n",
    "        for i in range(0, im.shape[0], patch_size):\n",
    "            patch = im[i:i + patch_size, j:j + patch_size]\n",
    "            label = patch_to_label(patch)\n",
    "            yield(\"{:03d}_{}_{},{}\".format(img_number, j, i, label))\n",
    "\n",
    "\n",
    "def masks_to_submission(submission_filename, *image_filenames):\n",
    "    \"\"\"Converts images into a submission file\"\"\"\n",
    "    with open(submission_filename, 'w') as f:\n",
    "        f.write('id,prediction\\n')\n",
    "        for fn in image_filenames[0:]:\n",
    "            f.writelines('{}\\n'.format(s) for s in mask_to_submission_strings(fn))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    submission_filename = 'dummy_submission.csv'\n",
    "    image_filenames = []\n",
    "    for i in range(1, 51):\n",
    "        image_filename = 'training/groundtruth/satImage_' + '%.3d' % i + '.png'\n",
    "        image_filenames.append(image_filename)\n",
    "    masks_to_submission(submission_filename, *image_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loaded a set of images\n",
    "root_dir_test = \"test_set_images/\"\n",
    "imgs_test = []\n",
    "for l in range(1,51):\n",
    "    dir_test = root_dir_test + 'test_'+str(l)+'/'\n",
    "    files_test = os.listdir(dir_test)\n",
    "    img_test = load_image(dir_test + files_test[0])\n",
    "    imgs_test.append(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_masks = create_submission(imgs_test, models, 16, 16, 'Submission_first', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_masks[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in range(len(list_of_masks)):\n",
    "    name = 'image_' + str(k)\n",
    "    my_df = pd.DataFrame(list_of_masks[k])\n",
    "    my_df.to_csv(name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PER DIEGO: ASSICURATI DI AVERE GLI EXCEL NELLA STESSA FOLDER DELLA CARTELLLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valerio caro, LEVA VIA STA ROBACCIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "result=[]\n",
    "for k in range(50):\n",
    "    df = pd.read_csv('image_'+str(k)+'.csv').iloc[:,1:]\n",
    "    matrix = df.values\n",
    "    result.append(matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULT: LISTA DI MATRICI 608 * 608"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('image_'+str(0)+'.csv').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix = df.values\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "my_df = pd.DataFrame(list_of_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=90*3\n",
    "N=len(imgs)\n",
    "train_imgs=imgs[0:n]\n",
    "train_mask=gt_imgs[0:n]\n",
    "test_imgs=imgs[n:N]\n",
    "test_mask = gt_imgs[n:N]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp=concatenate_images(train_imgs[3], train_mask[3])\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? tc.nn.Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(train_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(test_imgs),N-n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare input data \n",
    "w=16\n",
    "h=16\n",
    "train_sub_images=[img_crop(train_imgs[i], w, h) for i in range(n)]\n",
    "train_mask_label=[img_crop(train_mask[i],w,h) for i in range(n)]\n",
    "train_mask_label=from_mask_to_vector(train_mask_label,0.3)\n",
    "test_sub_images=[img_crop(test_imgs[i], w, h) for i in range(N-n)]\n",
    "#test_mask_label=[img_crop(train_mask[n+i],w,h) for i in range(n)]\n",
    "#test_mask_label=from_mask_to_vector(test_mask_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print((1*train_mask_label).sum()/len(train_mask_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(train_sub_images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sub_images = transform_subIMG_to_Tensor(train_sub_images)\n",
    "test_sub_images = transform_subIMG_to_Tensor(test_sub_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# normalize data\n",
    "mean = train_sub_images.mean()\n",
    "std = train_sub_images.std()\n",
    "train_sub_images = (train_sub_images-mean)/std\n",
    "train_sub_images, train_mask_label = reduce_dataset(train_sub_images,train_mask_label)\n",
    "#print(train_sub_images[-1]-train_sub_images[-2])\n",
    "for l in range(n):\n",
    "    new_indices= np.random.permutation(len(train_mask_label))\n",
    "    train_sub_images=train_sub_images[new_indices]\n",
    "    train_mask_label=train_mask_label[new_indices]\n",
    "#print(train_sub_images[0]-train_sub_images[1])\n",
    "#train_sub_images.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " ? tc.Tensor.narrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_mask_label.sum()/len(train_mask_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SimpleNet(0)\n",
    "lr=1e-4\n",
    "max_epochs=15\n",
    "mini_batch_size=1\n",
    "\n",
    "train_model_Adam( model, train_sub_images, train_mask_label, max_epochs, lr, mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(tc.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? tc.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N1=625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the result on a single image\n",
    "#N1=int(train_sub_images.size(0)/n)\n",
    "image_test= test_sub_images.narrow(0,43*N1,N1)\n",
    "image_test=(image_test-mean)/std\n",
    "mask_array=model(image_test)\n",
    "#print(mask_array.max())\n",
    "mask_list=mask_array[:]>0.5\n",
    "mask_test = label_to_img(400, 400, 16, 16, mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute F1 score\n",
    "mask=gt_imgs[n]\n",
    "#print(mask.sum())\n",
    "print(calcul_F1(mask, mask_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# overlap images\n",
    "\n",
    "print_img = make_img_overlay(imgs[n+43], mask_test)\n",
    "#print_img = make_img_overlay(imgs[n+43], gt_imgs[n+43])\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(print_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_test_error(test_dataset, test_label, nb_patches, model):\n",
    "    ''' compute the F1 error made during road segmentation. \n",
    "    Exemple: for a 16*16 patch we have that nb_patches=625'''\n",
    "    model.is_train=False\n",
    "    mean=test_dataset.mean()\n",
    "    std= test_dataset.std()\n",
    "    test_dataset = (test_dataset-mean)/std\n",
    "    test_output = model(test_dataset)\n",
    "    w = int(400/np.sqrt(nb_patches))\n",
    "    F1_error=np.zeros(int(test_dataset.size(0)/nb_patches))\n",
    "    for i in range(int(test_dataset.size(0)/nb_patches)):\n",
    "        mask = test_output.narrow(0,i*nb_patches, nb_patches)\n",
    "        mask = mask.detach().numpy()[:]>0.5\n",
    "        mask = label_to_img(400, 400, w, w, mask)\n",
    "        F1_error[i] = calcul_F1(test_label[i], mask)\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(int(test_dataset.size(0)/nb_patches))+1,F1_error)\n",
    "    plt.xlabel('image')\n",
    "    plt.ylabel('F1_error')\n",
    "    F1_mean= np.mean(F1_error)\n",
    "    return F1_mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F1=compute_test_error(test_sub_images, test_mask, 625, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
