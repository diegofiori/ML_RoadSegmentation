{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch as tc\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from helpers_img import *\n",
    "from NeuralNets import *\n",
    "from training_NN import *\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valerio inizia da qui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 100 images\n",
      "satImage_042.png\n",
      "Loading 100 images\n",
      "satImage_042.png\n"
     ]
    }
   ],
   "source": [
    "# Loaded a set of images\n",
    "root_dir = \"training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "N = min(100, len(files)) # Load maximum 100 images\n",
    "print(\"Loading \" + str(N) + \" images\")\n",
    "imgs = [load_image(image_dir + files[i]) for i in range(N)]\n",
    "print(files[0])\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(N) + \" images\")\n",
    "gt_imgs = [load_image(gt_dir + files[i]) for i in range(N)]\n",
    "print(files[0])\n",
    "\n",
    "#n = 85 # Only use 85 images for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DatasetUNet(tc.utils.data.Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.image_dir + root_dir + \"images/\"\n",
    "        self.files = os.listdir(self.image_dir)\n",
    "        self.gt_dir = root_dir + \"groundtruth/\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset,label = rotation(imgs, gt_imgs)\n",
    "dataset = preprocessing_for_UNet(dataset)\n",
    "dataset,label = flip(dataset,label)\n",
    "dataset = from_list_to_tensor(dataset)\n",
    "label = from_list_to_tensor(dataset)\n",
    "\n",
    "dataset = tc.utils.data.TensorDataset(dataset,label)\n",
    "dataset = tc.utils.data.DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = imgs[0]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = image.mean()\n",
    "std = image.std()\n",
    "\n",
    "noise = np.random.normal(mean,std/5,size = image.shape)\n",
    "image_noise = image + noise\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of imgages: 400\n"
     ]
    }
   ],
   "source": [
    "# augment the dataset adding rotated images\n",
    "imgs, gt_imgs = rotation(imgs, gt_imgs)\n",
    "print('Total number of imgages: '+str(len(imgs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UNet(tc.nn.Module):\n",
    "    def __init__(self,features=3):\n",
    "        super(UNet,self).__init__()\n",
    "        self.is_training=False\n",
    "        self.conv1 = tc.nn.Conv2d(features,8,kernel_size=3)\n",
    "        self.batch1 = tc.nn.BatchNorm2d(8)\n",
    "        self.conv2 = tc.nn.Conv2d(8,8, kernel_size=3)\n",
    "        self.batch2 = tc.nn.BatchNorm2d(8)\n",
    "        self.conv3 = tc.nn.Conv2d(8,16, kernel_size=3)\n",
    "        self.batch3 = tc.nn.BatchNorm2d(16)\n",
    "        self.conv4 = tc.nn.Conv2d(16,16, kernel_size=3)\n",
    "        self.batch4 = tc.nn.BatchNorm2d(16)\n",
    "        self.conv5 = tc.nn.Conv2d(16,16, kernel_size=4)\n",
    "        self.batch5 = tc.nn.BatchNorm2d(16)\n",
    "        self.convUp1 = tc.nn.ConvTranspose2d(16,16,stride=2,kernel_size=2)\n",
    "        self.conv6 = tc.nn.Conv2d(32,16, kernel_size=3)\n",
    "        self.batch6 = tc.nn.BatchNorm2d(16)\n",
    "        self.conv7 = tc.nn.Conv2d(16,16, kernel_size=3)\n",
    "        self.batch7 = tc.nn.BatchNorm2d(16)\n",
    "        self.convUp2 = tc.nn.ConvTranspose2d(16,8,stride=2,kernel_size=2)\n",
    "        self.conv8 = tc.nn.Conv2d(16,8, kernel_size=3)\n",
    "        self.batch8 = tc.nn.BatchNorm2d(8)\n",
    "        self.conv9 = tc.nn.Conv2d(8,8, kernel_size=3)\n",
    "        self.batch9 = tc.nn.BatchNorm2d(8)\n",
    "        self.convUp3 = tc.nn.ConvTranspose2d(8,4,kernel_size=39)\n",
    "        self.conv10 = tc.nn.Conv2d(4,1,kernel_size=3)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.batch1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #x1 = x.clone()\n",
    "        x1 = x\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = x = self.batch2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.batch3(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        #x2 = x.clone()\n",
    "        x2 = x\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = self.batch4(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.batch5(x)\n",
    "        \n",
    "        x = F.relu(self.convUp1(x))\n",
    "        \n",
    "        x= self.adapt_activation(x2,x)\n",
    "        \n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.batch6(x)\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = self.batch7(x)\n",
    "        \n",
    "        x = F.relu(self.convUp2(x))\n",
    "        \n",
    "        x = self.adapt_activation(x1,x)\n",
    "        \n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = self.batch8(x)\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = self.batch9(x)\n",
    "        \n",
    "        x = F.relu(self.convUp3(x))\n",
    "        x = tc.sigmoid(self.conv10(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def adapt_activation(self,x_old,x_new):\n",
    "        '''the function adapts the activation to the smaller one dimensions\n",
    "        and concatenates them'''\n",
    "        \n",
    "        space = (x_old.size(2)- x_new.size(2))//2\n",
    "        \n",
    "        distance = x_new.size(2)\n",
    "        \n",
    "        x_old = x_old.narrow(2,space,distance)\n",
    "        x_old = x_old.narrow(3,space,distance)\n",
    "        \n",
    "        x_new = tc.cat((x_old,x_new),dim=1)\n",
    "        \n",
    "        return x_new\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing_for_UNet(dataset):\n",
    "    # laplace\n",
    "    \n",
    "    for i,image in enumerate(dataset):\n",
    "        _, laplacian_image = add_laplacian(image)\n",
    "        sobel = add_sobel(image)\n",
    "        segment = add_segment(image)\n",
    "        dataset[i]=np.concatenate((image,laplacian_image,sobel,segment),axis = 2)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_noise(dataset,label, is_simple=True):\n",
    "    '''Add noise to the dataset.\n",
    "    \n",
    "    dataset : tensor type\n",
    "    \n",
    "    label : tensor type'''\n",
    "    \n",
    "    \n",
    "    if is_simple:\n",
    "        \n",
    "        mean, std = dataset.mean(), dataset.std()\n",
    "        # the noise has the 20% of the image standard deviation\n",
    "        noise = np.random.normal(loc = mean, scale = std/5, size = dataset.size())\n",
    "        \n",
    "\n",
    "        dataset_with_noise = dataset + tc.tensor(noise).type(tc.FloatTensor)\n",
    "        dataset = tc.cat((dataset,dataset_with_noise),dim = 0)\n",
    "        label = label.type(tc.FloatTensor)\n",
    "        label = tc.cat((label, label), dim = 0)\n",
    "    else:\n",
    "        \n",
    "        mean, std = 0, 0.05\n",
    "        \n",
    "        noise = np.random.normal(mean, std, size = label.size())\n",
    "        \n",
    "        label.type(float)\n",
    "        \n",
    "        label_with_noise = label + tc.tensor(noise).type(tc.FloatTensor)\n",
    "        \n",
    "        label = tc.cat((label,label_with_noise),dim=0)\n",
    "        \n",
    "        dataset = tc.cat((dataset,dataset),dim=0)\n",
    "    \n",
    "    return dataset, label\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def from_list_to_tensor(dataset):\n",
    "    ''' cast a list of image in a tensor of appropriate size'''\n",
    "    dataset = np.array(dataset)\n",
    "    try :\n",
    "        N,rows,columns,features = dataset.shape\n",
    "    except:\n",
    "        N,rows,columns = dataset.shape\n",
    "        features=1\n",
    "        dataset=dataset.reshape(N,rows,columns,features)\n",
    "        \n",
    "    dataset_tensor = tc.Tensor(N, features, rows, columns)\n",
    "    for j in range(N):\n",
    "        dataset_tensor[j] = tc.tensor(np.array([dataset[j,:,:,i] for i in range(features)]))\n",
    "    \n",
    "    \n",
    "    return dataset_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_UNet(dataset, label, lr, max_epochs, mini_batch_size, nb_test, threshold=0.5, \n",
    "               do_preprocessing = False, flip_data=True, model=None):\n",
    "    ''' train the UNet using the Binary Cross Entropy loss and Adam as optimizer.\n",
    "    The dataset must be a list of 400*400 images.'''\n",
    "    \n",
    "    if flip_data: \n",
    "        dataset,label = flip(dataset,label)\n",
    "    \n",
    "    if do_preprocessing:\n",
    "        dataset = preprocessing_for_UNet(dataset)\n",
    "    \n",
    "    \n",
    "    dataset = from_list_to_tensor(dataset)\n",
    "    mean = dataset.mean()\n",
    "    std = dataset.std()\n",
    "    dataset = (dataset - mean)/ std\n",
    "    test= dataset.narrow(0,dataset.size(0)-nb_test,nb_test)\n",
    "    dataset = dataset.narrow(0,0,dataset.size(0)-nb_test)\n",
    "    label = from_list_to_tensor(label)\n",
    "    test_l = label.narrow(0,dataset.size(0),nb_test)\n",
    "    label = label.narrow(0,0,dataset.size(0))\n",
    "    \n",
    "    ## add is_simple = False to add noise to labels\n",
    "    dataset, label = add_noise(dataset, label)\n",
    "    if model == None:\n",
    "        model = UNet(features= dataset.size(1))\n",
    "    \n",
    "    optimizer=tc.optim.Adam(model.parameters(),lr)\n",
    "    # maybe using MSE is better\n",
    "    #criterion= tc.nn.BCELoss()\n",
    "    criterion = tc.nn.MSELoss()\n",
    "    training_errors=[]\n",
    "    losses=[]\n",
    "    \n",
    "    if tc.cuda.is_available():\n",
    "        print('cuda is available')\n",
    "        model.cuda()\n",
    "        #criterion.cuda()\n",
    "        test = test.cuda()\n",
    "        #dataset= dataset.cuda()\n",
    "        #label = label.cuda()\n",
    "    \n",
    "    #training_F1_error=[]\n",
    "    #print('starting to train the net')\n",
    "    for epoch in tqdm(range(max_epochs)):\n",
    "        model.train()\n",
    "        #if tc.cuda.is_available():\n",
    "        #    model.cuda()\n",
    "        for j in range(0,dataset.size(0)-nb_test,mini_batch_size):\n",
    "            input_data = dataset.narrow(0,j,mini_batch_size)\n",
    "            label_data = label.narrow(0,j,mini_batch_size)\n",
    "            if tc.cuda.is_available():\n",
    "                input_data, label_data = input_data.cuda(), label_data.cuda()\n",
    "            output = model(input_data)\n",
    "            #print(output, label_data)\n",
    "            loss = criterion(output, label_data)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tc.cuda.empty_cache()\n",
    "            \n",
    "        \n",
    "        # compute training error\n",
    "        model.eval()\n",
    "        losses.append(loss)\n",
    "        prediction = model(test)\n",
    "        prediction = prediction.cpu()\n",
    "        prediction = prediction.detach_().numpy()[:,0,:,:]\n",
    "        prediction = (prediction > threshold)*1\n",
    "        #print(prediction[0])\n",
    "        mask = test_l.numpy()[:,0,:,:]\n",
    "        F1_error = 0\n",
    "        #print(mask.shape)\n",
    "        training_error = (((mask>0.5)*1 == prediction)*1).sum()/np.prod(prediction.shape)\n",
    "        \n",
    "        training_errors.append(training_error)\n",
    "        \n",
    "        \n",
    "        # improve the calcul_F1 fonction to optimize the code\n",
    "        '''\n",
    "        for i in range(dataset.size(0)):\n",
    "            F1_error += calcul_F1(mask[i], prediction[i])\n",
    "        F1_error = F1_error/dataset.size(0)\n",
    "        training_F1_error.append(F1_error)\n",
    "        if F1_error >0.95:\n",
    "            break\n",
    "        \n",
    "    # plot the results\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(epoch + 1)+1,training_F1_error)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('F1_error')\n",
    "    '''\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(epoch + 1)+1,losses)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(epoch + 1)+1,training_errors)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    return model\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? datasets.ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(tc.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tc.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let's start to train the Net\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "$ Torch: not enough memory: you tried to allocate 4GB. Buy new RAM! at /opt/conda/conda-bld/pytorch_1544081127912/work/aten/src/TH/THGeneral.cpp:201",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1aac65d1b9f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'let\\'s start to train the Net'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_UNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_preprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-d39c7e240d81>\u001b[0m in \u001b[0;36mtrain_UNet\u001b[0;34m(dataset, label, lr, max_epochs, mini_batch_size, nb_test, threshold, do_preprocessing, flip_data, model)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m## add is_simple = False to add noise to labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-47877d6ee094>\u001b[0m in \u001b[0;36madd_noise\u001b[0;34m(dataset, label, is_simple)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mdataset_with_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset_with_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 4GB. Buy new RAM! at /opt/conda/conda-bld/pytorch_1544081127912/work/aten/src/TH/THGeneral.cpp:201"
     ]
    }
   ],
   "source": [
    "N = len(imgs)\n",
    "n = N\n",
    "train_imgs=imgs[0:n]\n",
    "train_mask=gt_imgs[0:n]\n",
    "#test_imgs=imgs[n:N]\n",
    "#test_mask = gt_imgs[n:N]\n",
    "lr = 1e-4\n",
    "max_epochs = 50\n",
    "mini_batch_size=10\n",
    "nb_test = 10\n",
    "print('let\\'s start to train the Net')\n",
    "\n",
    "model = train_UNet(train_imgs, train_mask, lr, max_epochs, mini_batch_size,nb_test, do_preprocessing=True, model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "tc.save(model,'Model_UNet/model_CPU.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = tc.load('Model_UNet/model_CPU.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on a image\n",
    "image = [imgs[4]]\n",
    "image = preprocessing_for_UNet(image)\n",
    "image = from_list_to_tensor(image)\n",
    "image = (image - image.mean())/image.std()\n",
    "model.eval()\n",
    "prediction = model(image)\n",
    "print(prediction.size())\n",
    "prediction =  prediction.detach_().numpy()[0,0,:,:]\n",
    "prediction = (prediction > 0.5)*1\n",
    "#mask = gt_imgs[20]\n",
    "mask = prediction\n",
    "image = make_img_overlay(imgs[4],mask)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_submission_UNet(test_set, model, name_submission, do_preprocessing= False):\n",
    "    ''' create the submission file for U-Net.\n",
    "    \n",
    "    test_set is a list of images'''\n",
    "    \n",
    "    # preprocessing\n",
    "    \n",
    "    if do_preprocessing:\n",
    "        test_set = preprocessing_for_UNet(test_set)\n",
    "        \n",
    "    # transform list of images in tensor \n",
    "    print('a')\n",
    "    test_set = from_list_to_tensor(test_set)\n",
    "    print('a')\n",
    "    test_set = (test_set- test_set.mean())/test_set.std()\n",
    "    model.eval()\n",
    "    \n",
    "    mini_batch = 10\n",
    "    print('a')\n",
    "    N,channel,w,h = test_set.size()\n",
    "    if tc.cuda.is_available():\n",
    "        model.cuda()\n",
    "    \n",
    "    mask = tc.Tensor(N,1,w,h)\n",
    "    batch_size=10\n",
    "    for i in range(0,test_set.size(0),mini_batch):\n",
    "        temp =  test_set.narrow(0,i,mini_batch)\n",
    "        print(temp.size())\n",
    "        if tc.cuda.is_available():\n",
    "            tc.cuda.empty_cache()\n",
    "            temp = temp.cuda()\n",
    "        temp = model(temp)\n",
    "        mask[i:i+batch_size] = temp.cpu()\n",
    "    print('a')\n",
    "    mask = (mask.detach().numpy() > 0.5)*1\n",
    "    list_of_names= []\n",
    "    for i in range(N):\n",
    "        plt.imsave( \"prediction_\"+str(i+1)+\".png\", mask[i], cmap = matplotlib.cm.gray)\n",
    "        list_of_names.append(\"prediction_\"+str(i+1)+\".png\")\n",
    "    masks_to_submission(name_submission, *list_of_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loaded a set of images\n",
    "root_dir_test = \"test_set_images/\"\n",
    "imgs_test = []\n",
    "for l in range(1,51):\n",
    "    dir_test = root_dir_test + 'test_'+str(l)+'/'\n",
    "    files_test = os.listdir(dir_test)\n",
    "    img_test = load_image(dir_test + files_test[0])\n",
    "    imgs_test.append(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission_UNet(imgs_test, model, 'third_submission.csv', do_preprocessing= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=90*3\n",
    "N=len(imgs)\n",
    "train_imgs=imgs[0:n]\n",
    "train_mask=gt_imgs[0:n]\n",
    "test_imgs=imgs[n:N]\n",
    "test_mask = gt_imgs[n:N]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp=concatenate_images(train_imgs[3], train_mask[3])\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? tc.nn.Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(train_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(test_imgs),N-n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare input data \n",
    "w=16\n",
    "h=16\n",
    "train_sub_images=[img_crop(train_imgs[i], w, h) for i in range(n)]\n",
    "train_mask_label=[img_crop(train_mask[i],w,h) for i in range(n)]\n",
    "train_mask_label=from_mask_to_vector(train_mask_label,0.3)\n",
    "test_sub_images=[img_crop(test_imgs[i], w, h) for i in range(N-n)]\n",
    "#test_mask_label=[img_crop(train_mask[n+i],w,h) for i in range(n)]\n",
    "#test_mask_label=from_mask_to_vector(test_mask_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? Image.fromarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print((1*train_mask_label).sum()/len(train_mask_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(train_sub_images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sub_images = transform_subIMG_to_Tensor(train_sub_images)\n",
    "test_sub_images = transform_subIMG_to_Tensor(test_sub_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# normalize data\n",
    "mean = train_sub_images.mean()\n",
    "std = train_sub_images.std()\n",
    "train_sub_images = (train_sub_images-mean)/std\n",
    "train_sub_images, train_mask_label = reduce_dataset(train_sub_images,train_mask_label)\n",
    "#print(train_sub_images[-1]-train_sub_images[-2])\n",
    "for l in range(n):\n",
    "    new_indices= np.random.permutation(len(train_mask_label))\n",
    "    train_sub_images=train_sub_images[new_indices]\n",
    "    train_mask_label=train_mask_label[new_indices]\n",
    "#print(train_sub_images[0]-train_sub_images[1])\n",
    "#train_sub_images.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " ? tc.Tensor.narrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_mask_label.sum()/len(train_mask_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SimpleNet(0)\n",
    "lr=1e-4\n",
    "max_epochs=15\n",
    "mini_batch_size=1\n",
    "\n",
    "train_model_Adam( model, train_sub_images, train_mask_label, max_epochs, lr, mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(tc.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? tc.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N1=625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the result on a single image\n",
    "#N1=int(train_sub_images.size(0)/n)\n",
    "image_test= test_sub_images.narrow(0,43*N1,N1)\n",
    "image_test=(image_test-mean)/std\n",
    "mask_array=model(image_test)\n",
    "#print(mask_array.max())\n",
    "mask_list=mask_array[:]>0.5\n",
    "mask_test = label_to_img(400, 400, 16, 16, mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute F1 score\n",
    "mask=gt_imgs[n]\n",
    "#print(mask.sum())\n",
    "print(calcul_F1(mask, mask_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# overlap images\n",
    "\n",
    "print_img = make_img_overlay(imgs[n+43], mask_test)\n",
    "#print_img = make_img_overlay(imgs[n+43], gt_imgs[n+43])\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(print_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_test_error(test_dataset, test_label, nb_patches, model):\n",
    "    ''' compute the F1 error made during road segmentation. \n",
    "    Exemple: for a 16*16 patch we have that nb_patches=625'''\n",
    "    model.is_train=False\n",
    "    mean=test_dataset.mean()\n",
    "    std= test_dataset.std()\n",
    "    test_dataset = (test_dataset-mean)/std\n",
    "    test_output = model(test_dataset)\n",
    "    w = int(400/np.sqrt(nb_patches))\n",
    "    F1_error=np.zeros(int(test_dataset.size(0)/nb_patches))\n",
    "    for i in range(int(test_dataset.size(0)/nb_patches)):\n",
    "        mask = test_output.narrow(0,i*nb_patches, nb_patches)\n",
    "        mask = mask.detach().numpy()[:]>0.5\n",
    "        mask = label_to_img(400, 400, w, w, mask)\n",
    "        F1_error[i] = calcul_F1(test_label[i], mask)\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(int(test_dataset.size(0)/nb_patches))+1,F1_error)\n",
    "    plt.xlabel('image')\n",
    "    plt.ylabel('F1_error')\n",
    "    F1_mean= np.mean(F1_error)\n",
    "    return F1_mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F1=compute_test_error(test_sub_images, test_mask, 625, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
