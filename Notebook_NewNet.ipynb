{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch as tc\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import TensorDataset\n",
    "from helpers_img import *\n",
    "from NeuralNets import *\n",
    "from training_NN import *\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try to improve simple_net predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define A NewNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DeepNet(tc.nn.Module):\n",
    "    def __init__(self,dropout,features=3):\n",
    "        super(DeepNet,self).__init__()\n",
    "        self.conv1=tc.nn.Conv2d(features,16,kernel_size=(3,3))\n",
    "        self.pool1= tc.nn.MaxPool2d(kernel_size = (2,2))\n",
    "        self.drop1=tc.nn.Dropout(dropout)\n",
    "        self.batch1=tc.nn.BatchNorm2d(16)\n",
    "        self.conv2=tc.nn.Conv2d(16,16,kernel_size=(4,4))\n",
    "        self.pool2 = tc.nn.MaxPool2d(kernel_size = (2,2))\n",
    "        self.drop2=tc.nn.Dropout(dropout)\n",
    "        self.batch12=tc.nn.BatchNorm2d(16)\n",
    "        self.conv3=tc.nn.Conv2d(16,31,kernel_size=(3,3))\n",
    "        self.pool3= tc.nn.MaxPool2d(kernel_size = (2,1))\n",
    "        self.drop3=tc.nn.Dropout(dropout)\n",
    "        self.batch12=tc.nn.BatchNorm2d(32)\n",
    "        self.conv4=tc.nn.Conv2d(32,1,kernel_size=(2,2))\n",
    "        self.pool4 = tc.nn.MaxPool2d(kernel_size = (2,1))\n",
    "        self.drop4=tc.nn.Dropout(dropout)\n",
    "        # Net created for input_files 16*16\n",
    "        self.fc1=tc.nn.Linear(7,7)\n",
    "        self.drop5 = tc.nn.Dropout(dropout)\n",
    "        self.fc2=tc.nn.Linear(7,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.pool1(self.conv1(x)))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.pool2(self.conv2(x)))\n",
    "        x = self.drop2(x)\n",
    "        x = F.relu(self.pool3(self.conv3(x)))\n",
    "        x = self.drop3(x)\n",
    "        x = F.relu(self.pool4(self.conv4(x)))\n",
    "        x = self.drop4(x)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop5(x)\n",
    "        x= tc.sigmoid(self.fc2(x))\n",
    "        #x = self.fc2(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "? tc.nn.MaxPool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_crop_mod(im, w, h):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(h,imgheight-h,h):\n",
    "        for j in range(w,imgwidth-w,w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j-w:j+2*w, i-h:i+2*h]\n",
    "            else:\n",
    "                im_patch = im[j-w:j+2*w, i-h:i+2*h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DatasetDeepNet(Dataset):\n",
    "    def __init__(self,root_dir, do_flip=False, do_rotation=False,do_train=False):\n",
    "        self.image_dir = root_dir + \"images/\"\n",
    "        self.files = os.listdir(self.image_dir)\n",
    "        self.gt_dir = root_dir + \"groundtruth/\"\n",
    "        self.rot_len=0\n",
    "        self.flip_len=0\n",
    "        self.train = do_train\n",
    "        self.initial_len=len(self.files)\n",
    "        # rotation\n",
    "        if do_rotation:\n",
    "            self.rot_len= len(self.files)\n",
    "            self.files = [*self.files*4]\n",
    "        #flip \n",
    "        if do_flip:\n",
    "            self.flip_len=len(self.files)\n",
    "            self.files= [*self.files*2]\n",
    "        \n",
    "                \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        image = [load_image(self.image_dir + self.files[index])]\n",
    "        gt_image = [load_image(self.gt_dir + self.files[index])]\n",
    "        if self.rot_len>0:\n",
    "            image,gt_image = rotation(image,gt_image)\n",
    "        if self.flip_len>0:\n",
    "            image,gt_image = flip(image,gt_image)\n",
    "        \n",
    "        i = index//self.initial_len\n",
    "        image,gt_image = image[i],gt_image[i]\n",
    "        add_border(image,432)\n",
    "        train_sub_images = [img_crop_mod(image, 40, 40)]\n",
    "        train_mask_label = [img_crop(gt_image,16,16)]\n",
    "        train_mask_label = from_mask_to_vector(train_mask_label,0.3)\n",
    "        train_sub_images = transform_subIMG_to_Tensor(train_sub_images)\n",
    "        mean = train_sub_images.mean()\n",
    "        std = train_sub_images.std()\n",
    "        train_sub_images = (train_sub_images-mean)/std\n",
    "        if self.train:\n",
    "            train_sub_images, train_mask_label = reduce_dataset(train_sub_images,train_mask_label)\n",
    "            for l in range(10):\n",
    "                new_indices= np.random.permutation(len(train_mask_label))\n",
    "                train_sub_images=train_sub_images[new_indices]\n",
    "                train_mask_label=train_mask_label[new_indices]\n",
    "        return train_sub_images, train_mask_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model_Adam_v2( model, dataset, max_epochs, lr, mini_batch_size, w=40, h=40, features=3, threshold=0.01):\n",
    "    '''train the Neural Net using Adam as optimizer and an binary cross entropy loss'''\n",
    "    #optimizer=tc.optim.SGD(model.parameters(),lr)\n",
    "    train_loader = DataLoader(dataset,batch_size=mini_batch_size)\n",
    "    optimizer=tc.optim.Adam(model.parameters(),lr)\n",
    "    criterion= tc.nn.BCELoss()\n",
    "    losses=[]\n",
    "    training_errors = []\n",
    "    if tc.cuda.is_available():\n",
    "        model.cuda()\n",
    "        \n",
    "    \n",
    "    for epoch in tqdm(range(max_epochs)):\n",
    "        model.is_training=True\n",
    "        model.train()\n",
    "    \n",
    "        for train_data,label in train_loader:\n",
    "            train_data = train_data.view(-1,features,w,h)\n",
    "            label = label.view(-1,1)\n",
    "            if tc.cuda.is_available():\n",
    "                train_data = train_data.cuda()\n",
    "                label = label.cuda()\n",
    "            output= model(train_data)\n",
    "            #print(output,tc.LongTensor(np.array([1*label[i:i+mini_batch_size]]).reshape(-1,1)))\n",
    "            loss= criterion(output,label)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        losses.append(loss)\n",
    "        # compute training error\n",
    "        model.is_training=False\n",
    "        model.eval()\n",
    "        test = model(train_data)\n",
    "        test = test.cpu()\n",
    "        prediction= test[:]>0.5\n",
    "        \n",
    "        prediction= 1*(prediction.numpy()[:] != label.reshape(-1,1)[:])\n",
    "        \n",
    "        training_error = np.sum(prediction)/len(prediction)\n",
    "        training_errors.append(training_error*100)\n",
    "        if training_error< threshold:\n",
    "            break\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(epoch+1)+1,training_errors)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('training_errors')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(epoch+1)+1,losses)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()\n",
    "    \n",
    "    model.cpu()    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainDeepNet(root_dir, max_epochs, lr, mini_batch_size, dropout=0, model = None):\n",
    "    if model == None:\n",
    "        model = DeepNet(dropout)\n",
    "    \n",
    "    dataset = DatasetDeepNet(root_dir, do_flip=True, do_rotation=True,do_train=True)\n",
    "    \n",
    "    model = train_model_Adam_v2( model, dataset, max_epochs, lr, mini_batch_size)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    " root_dir = 'training/'\n",
    "max_epochs = 15\n",
    "lr = 1e-4\n",
    "mini_batch_size = 10\n",
    "model = trainDeepNet(root_dir, max_epochs, lr, mini_batch_size, model = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
