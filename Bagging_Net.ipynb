{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch as tc\n",
    "from helpers_img import *\n",
    "from NeuralNets import *\n",
    "from training_NN import *\n",
    "from Post_processing import *\n",
    "from submission import *\n",
    "from Bagging_Net import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tc.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loaded a set of images\n",
    "root_dir = \"training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "N = min(100, len(files)) # Load maximum 100 images\n",
    "print(\"Loading \" + str(N) + \" images\")\n",
    "imgs = [load_image(image_dir + files[i]) for i in range(N)]\n",
    "print(files[0])\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(N) + \" images\")\n",
    "gt_imgs = [load_image(gt_dir + files[i]) for i in range(N)]\n",
    "print(files[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# augment the dataset adding rotated images\n",
    "imgs, gt_imgs = rotation(imgs, gt_imgs)\n",
    "print('Total number of images: '+str(len(imgs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and train the list of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "percentage_train_data=0.1\n",
    "nb_model=10\n",
    "w=16\n",
    "h=16\n",
    "lr=1e-4\n",
    "max_epochs=20\n",
    "mini_batch_size=10\n",
    "dropout=0\n",
    "models, F1_error= bagging_NN(imgs, gt_imgs, percentage_train_data, nb_model, w, h, lr, max_epochs, mini_batch_size, dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the models for future needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,model in enumerate(models):\n",
    "    tc.save(model,f'Model_Bagging/model{i}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models=[]\n",
    "for i in range(10):\n",
    "    model = tc.load(f'Model_Bagging/model{i}.pt')\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the prediction of the models on a image taken from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_img = imgs[30]\n",
    "mask= gt_imgs[30]\n",
    "test_img = [img_crop(test_img, 16,16)]\n",
    "test_img = transform_subIMG_to_Tensor(test_img)\n",
    "mean=test_img.mean()\n",
    "std= test_img.std()\n",
    "test_img = (test_img-mean)/std\n",
    "result=np.zeros((test_img.size(0),))\n",
    "for model in models:\n",
    "    result += model(test_img).detach_().numpy().reshape(-1,)\n",
    "\n",
    "result = result / len(models)\n",
    "result = (result > 0.5)*1\n",
    "\n",
    "\n",
    "image = imgs[30]\n",
    "\n",
    "mask_res = label_to_img(400, 400, 16, 16, result)\n",
    "image_plot = make_img_overlay(image, mask_res)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image_plot)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test image, than plot a prediction and finally create the file submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loaded a set of images\n",
    "root_dir_test = \"test_set_images/\"\n",
    "imgs_test = []\n",
    "for l in range(1,51):\n",
    "    dir_test = root_dir_test + 'test_'+str(l)+'/'\n",
    "    files_test = os.listdir(dir_test)\n",
    "    img_test = load_image(dir_test + files_test[0])\n",
    "    imgs_test.append(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_image_test_bagging(imgs_test[16], models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_submission(imgs_test, models, w, h, 'submission_bagging.csv', '', normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
